{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "import datetime\n",
    "from sklearn.metrics import fbeta_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data_path', 'feature_dict', 'feature_path', 'model_features', 'result_path', 'single_module_validation_indice_set', 'trade_train_size', 'train_2_6_index']\n",
      "dict_keys(['trade_and_recent_login_comparing', 'recent_login_detail', 'trade_detail_feature', 'login_trade_hist_stats', 'llc_user_habbit', 'hcc_user_habbit', 'hcc_properties', 'hcc_target_encoding'])\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    pass\n",
    "config = pd.read_pickle('config.pkl')\n",
    "data_path = config.data_path\n",
    "feature_path = config.feature_path\n",
    "print(dir(config))\n",
    "print(config.feature_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model define\n",
    "\n",
    "def f_beta_01(preds, train_data):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(labels, preds > 0.8,0.1),True\n",
    "\n",
    "    \n",
    "#for binary\n",
    "def runLGBM(train_X, train_y, test_X, test_y=None, feature_names=None,\n",
    "           seed_val=0, num_rounds=10000,watch_dict = None,max_bin=50000,\n",
    "           num_leaves=16,early_stop=64,verbose=True,eta=0.1,\n",
    "           bagging_fraction = 0.75 , feature_fraction = 0.75,feval = None,metric = 'binary_logloss',\n",
    "           train_sample_weight = None):\n",
    "    \n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': eta,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': verbose,\n",
    "        'is_unbalance':False\n",
    "    }\n",
    "    \n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    #plst = list(param.items())\n",
    "    lgbtrain = lgb.Dataset(train_X, label=train_y,max_bin=max_bin,feature_name=feature_names,weight =train_sample_weight)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgbtest = lgb.Dataset(test_X, label=test_y,max_bin=max_bin,feature_name=feature_names)\n",
    "        watchlist = [lgbtrain,lgbtest]\n",
    "        watchlist_name=['train','test']\n",
    "        model = lgb.train(params, lgbtrain, num_rounds, watchlist,watchlist_name, early_stopping_rounds=early_stop,\\\n",
    "                         evals_result = watch_dict,verbose_eval=verbose,feval = feval)\n",
    "    else:\n",
    "        #lgbtest = lgb.Dataset(test_X,feature_name=feature_names)\n",
    "        model = lgb.train(params, lgbtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features =   (config.feature_dict['trade_detail_feature']+\n",
    "              config.feature_dict['recent_login_detail']+\n",
    "              config.feature_dict['trade_and_recent_login_comparing']+\n",
    "              config.feature_dict['login_trade_hist_stats']+\n",
    "              config.feature_dict['llc_user_habbit']+\n",
    "             config.feature_dict['hcc_user_habbit']+\n",
    "              config.feature_dict['hcc_properties']+\n",
    "            config.feature_dict['hcc_target_encoding']\n",
    "             )\n",
    "feature_sequence_list = []\n",
    "for feature in features:\n",
    "    feature_sequence_list.append(pd.read_pickle(feature_path+feature+'.pkl').reshape(-1,1))\n",
    "    \n",
    "trade_tt_mat = np.hstack(feature_sequence_list)\n",
    "#trade_tt_mat[trade_tt_mat==-10]=np.nan\n",
    "\n",
    "validation_tuple_list = config.single_module_validation_indice_set\n",
    "train_labels = pd.read_pickle(data_path+'trade_train_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features =  config.model_features['model_h1_top250']\n",
    "top_features_ori_index = [features.index(x) for x in top_features]\n",
    "trade_tt_top = trade_tt_mat[:,top_features_ori_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's auc: 0.989386\ttrain's fbeta_score_01: 0.978086\ttest's auc: 0.983628\ttest's fbeta_score_01: 0.930114\n",
      "[200]\ttrain's auc: 0.995165\ttrain's fbeta_score_01: 0.983061\ttest's auc: 0.988846\ttest's fbeta_score_01: 0.938153\n",
      "[300]\ttrain's auc: 0.998795\ttrain's fbeta_score_01: 0.989585\ttest's auc: 0.990473\ttest's fbeta_score_01: 0.928802\n",
      "[400]\ttrain's auc: 0.99973\ttrain's fbeta_score_01: 0.997374\ttest's auc: 0.988991\ttest's fbeta_score_01: 0.918873\n",
      "[500]\ttrain's auc: 0.999923\ttrain's fbeta_score_01: 0.997862\ttest's auc: 0.987941\ttest's fbeta_score_01: 0.913935\n",
      "f_beta score for the turn 1 is 0.913935250352\n",
      "[100]\ttrain's auc: 0.993271\ttrain's fbeta_score_01: 0.979589\ttest's auc: 0.96636\ttest's fbeta_score_01: 0.96404\n",
      "[200]\ttrain's auc: 0.997702\ttrain's fbeta_score_01: 0.987054\ttest's auc: 0.971493\ttest's fbeta_score_01: 0.967788\n",
      "[300]\ttrain's auc: 0.999469\ttrain's fbeta_score_01: 0.992973\ttest's auc: 0.970444\ttest's fbeta_score_01: 0.950817\n",
      "[400]\ttrain's auc: 0.999862\ttrain's fbeta_score_01: 0.998199\ttest's auc: 0.971979\ttest's fbeta_score_01: 0.951932\n",
      "[500]\ttrain's auc: 0.999977\ttrain's fbeta_score_01: 0.998762\ttest's auc: 0.97138\ttest's fbeta_score_01: 0.950817\n",
      "f_beta score for the turn 2 is 0.950816522574\n",
      "[100]\ttrain's auc: 0.993991\ttrain's fbeta_score_01: 0.991152\ttest's auc: 0.98001\ttest's fbeta_score_01: 0.955741\n",
      "[200]\ttrain's auc: 0.997589\ttrain's fbeta_score_01: 0.989223\ttest's auc: 0.98446\ttest's fbeta_score_01: 0.946811\n",
      "[300]\ttrain's auc: 0.999345\ttrain's fbeta_score_01: 0.991966\ttest's auc: 0.984931\ttest's fbeta_score_01: 0.948073\n",
      "[400]\ttrain's auc: 0.999817\ttrain's fbeta_score_01: 0.996153\ttest's auc: 0.986393\ttest's fbeta_score_01: 0.948482\n",
      "[500]\ttrain's auc: 0.99994\ttrain's fbeta_score_01: 0.998282\ttest's auc: 0.986589\ttest's fbeta_score_01: 0.948886\n",
      "f_beta score for the turn 3 is 0.948886406938\n",
      "[100]\ttrain's auc: 0.99036\ttrain's fbeta_score_01: 0.976932\ttest's auc: 0.96438\ttest's fbeta_score_01: 0.990537\n",
      "[200]\ttrain's auc: 0.995977\ttrain's fbeta_score_01: 0.981909\ttest's auc: 0.976654\ttest's fbeta_score_01: 0.991492\n",
      "[300]\ttrain's auc: 0.99916\ttrain's fbeta_score_01: 0.986943\ttest's auc: 0.977289\ttest's fbeta_score_01: 0.975531\n",
      "[400]\ttrain's auc: 0.9998\ttrain's fbeta_score_01: 0.996062\ttest's auc: 0.978955\ttest's fbeta_score_01: 0.976077\n",
      "[500]\ttrain's auc: 0.999949\ttrain's fbeta_score_01: 0.998135\ttest's auc: 0.978744\ttest's fbeta_score_01: 0.975531\n",
      "f_beta score for the turn 4 is 0.975531229878\n",
      "[100]\ttrain's auc: 0.990827\ttrain's fbeta_score_01: 0.97421\ttest's auc: 0.981832\ttest's fbeta_score_01: 0.914098\n",
      "[200]\ttrain's auc: 0.994116\ttrain's fbeta_score_01: 0.977807\ttest's auc: 0.984876\ttest's fbeta_score_01: 0.891359\n",
      "[300]\ttrain's auc: 0.999101\ttrain's fbeta_score_01: 0.987436\ttest's auc: 0.984585\ttest's fbeta_score_01: 0.885303\n",
      "[400]\ttrain's auc: 0.999779\ttrain's fbeta_score_01: 0.997643\ttest's auc: 0.9847\ttest's fbeta_score_01: 0.891359\n",
      "[500]\ttrain's auc: 0.999925\ttrain's fbeta_score_01: 0.998045\ttest's auc: 0.985155\ttest's fbeta_score_01: 0.892166\n",
      "f_beta score for the turn 5 is 0.892165522865\n",
      "[100]\ttrain's auc: 0.992044\ttrain's fbeta_score_01: 0.976925\ttest's auc: 0.974673\ttest's fbeta_score_01: 0.956171\n",
      "[200]\ttrain's auc: 0.996018\ttrain's fbeta_score_01: 0.979095\ttest's auc: 0.983755\ttest's fbeta_score_01: 0.959699\n",
      "[300]\ttrain's auc: 0.99875\ttrain's fbeta_score_01: 0.988221\ttest's auc: 0.985847\ttest's fbeta_score_01: 0.943152\n",
      "[400]\ttrain's auc: 0.999728\ttrain's fbeta_score_01: 0.997445\ttest's auc: 0.987081\ttest's fbeta_score_01: 0.958861\n",
      "[500]\ttrain's auc: 0.999912\ttrain's fbeta_score_01: 0.997999\ttest's auc: 0.986414\ttest's fbeta_score_01: 0.959699\n",
      "f_beta score for the turn 6 is 0.959698558322\n",
      "The mean of the cv_scores is: 0.940172248488\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_top[train_indice], trade_tt_top[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=top_features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=500,watch_dict=result_dict,feval = f_beta_01)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.8, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "#finding the best iteration\n",
    "pd_list = []\n",
    "for dic in cv_result:\n",
    "    pd_list.append(pd.DataFrame(dic['test']))\n",
    "for i in range(len(pd_list)):\n",
    "    pd_list[i].columns = pd_list[i].columns+'_'+str(i)\n",
    "validation_result = pd.concat(pd_list,axis = 1)\n",
    "validation_result['auc_avg'] = validation_result.apply(lambda x : np.mean([x.auc_0,x.auc_1,x.auc_2,x.auc_3,x.auc_4]),axis = 1)\n",
    "validation_result['fbeta_avg'] = validation_result.apply(lambda x : np.mean([x.fbeta_score_01_0,x.fbeta_score_01_1,\n",
    "                                                                     x.fbeta_score_01_2,x.fbeta_score_01_3,\n",
    "                                                                     x.fbeta_score_01_4]),axis=1)\n",
    "print(validation_result['auc_avg'].idxmax())\n",
    "print(validation_result['fbeta_avg'].idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X = trade_tt_mat[config.train_2_6_index]\n",
    "test_X = trade_tt_mat[config.trade_train_size:]\n",
    "train_y = train_labels[config.train_2_6_index]\n",
    "\n",
    "preds, _ = runLGBM(train_X, train_y, test_X, feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=450,watch_dict=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17875, 2)\n"
     ]
    }
   ],
   "source": [
    "result_path = '../../kaggleData/JD_logging/result/'\n",
    "test_rowkey = pd.read_pickle(data_path+'trade_test_rowkey.pkl')\n",
    "pred_label = pd.Series(preds > 0.8)\n",
    "result_set = pd.DataFrame(test_rowkey)\n",
    "result_set['is_risk'] = pred_label.astype(int)\n",
    "\n",
    "print(result_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(pred_label,result_path+'adding_type_h_450.pkl')\n",
    "result_set.to_csv(result_path+'adding_type_h_450.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
