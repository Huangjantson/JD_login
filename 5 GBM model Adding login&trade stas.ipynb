{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "import datetime\n",
    "from sklearn.metrics import fbeta_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data_path', 'feature_dict', 'feature_path', 'result_path', 'single_module_validation_indice_set', 'trade_train_size', 'train_2_6_index']\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    pass\n",
    "config = pd.read_pickle('config.pkl')\n",
    "data_path = config.data_path\n",
    "feature_path = config.feature_path\n",
    "print(dir(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'login_trade_hist_stats': ['after_fail_max_1',\n",
       "  'after_fail_max_15',\n",
       "  'after_fail_max_3',\n",
       "  'after_fail_max_30',\n",
       "  'after_fail_max_360',\n",
       "  'after_fail_max_7',\n",
       "  'after_fail_mean_1',\n",
       "  'after_fail_mean_15',\n",
       "  'after_fail_mean_3',\n",
       "  'after_fail_mean_30',\n",
       "  'after_fail_mean_360',\n",
       "  'after_fail_mean_7',\n",
       "  'after_fail_med_1',\n",
       "  'after_fail_med_15',\n",
       "  'after_fail_med_3',\n",
       "  'after_fail_med_30',\n",
       "  'after_fail_med_360',\n",
       "  'after_fail_med_7',\n",
       "  'after_fail_min_1',\n",
       "  'after_fail_min_15',\n",
       "  'after_fail_min_3',\n",
       "  'after_fail_min_30',\n",
       "  'after_fail_min_360',\n",
       "  'after_fail_min_7',\n",
       "  'after_fail_std_1',\n",
       "  'after_fail_std_15',\n",
       "  'after_fail_std_3',\n",
       "  'after_fail_std_30',\n",
       "  'after_fail_std_360',\n",
       "  'after_fail_std_7',\n",
       "  'login_fail_times_1',\n",
       "  'login_fail_times_15',\n",
       "  'login_fail_times_3',\n",
       "  'login_fail_times_30',\n",
       "  'login_fail_times_360',\n",
       "  'login_fail_times_7',\n",
       "  'login_success_rate_1',\n",
       "  'login_success_rate_15',\n",
       "  'login_success_rate_3',\n",
       "  'login_success_rate_30',\n",
       "  'login_success_rate_360',\n",
       "  'login_success_rate_7',\n",
       "  'login_success_times_1',\n",
       "  'login_success_times_15',\n",
       "  'login_success_times_3',\n",
       "  'login_success_times_30',\n",
       "  'login_success_times_360',\n",
       "  'login_success_times_7',\n",
       "  'login_times_1',\n",
       "  'login_times_15',\n",
       "  'login_times_3',\n",
       "  'login_times_30',\n",
       "  'login_times_360',\n",
       "  'login_times_7',\n",
       "  'multiple_fails_1',\n",
       "  'multiple_fails_15',\n",
       "  'multiple_fails_3',\n",
       "  'multiple_fails_30',\n",
       "  'multiple_fails_360',\n",
       "  'multiple_fails_7',\n",
       "  'timelong_max_1',\n",
       "  'timelong_max_15',\n",
       "  'timelong_max_3',\n",
       "  'timelong_max_30',\n",
       "  'timelong_max_360',\n",
       "  'timelong_max_7',\n",
       "  'timelong_mean_1',\n",
       "  'timelong_mean_15',\n",
       "  'timelong_mean_3',\n",
       "  'timelong_mean_30',\n",
       "  'timelong_mean_360',\n",
       "  'timelong_mean_7',\n",
       "  'timelong_med_1',\n",
       "  'timelong_med_15',\n",
       "  'timelong_med_3',\n",
       "  'timelong_med_30',\n",
       "  'timelong_med_360',\n",
       "  'timelong_med_7',\n",
       "  'timelong_min_1',\n",
       "  'timelong_min_15',\n",
       "  'timelong_min_3',\n",
       "  'timelong_min_30',\n",
       "  'timelong_min_360',\n",
       "  'timelong_min_7',\n",
       "  'timelong_std_1',\n",
       "  'timelong_std_15',\n",
       "  'timelong_std_3',\n",
       "  'timelong_std_30',\n",
       "  'timelong_std_360',\n",
       "  'timelong_std_7',\n",
       "  'trade_login_fail_rate_1',\n",
       "  'trade_login_fail_rate_15',\n",
       "  'trade_login_fail_rate_3',\n",
       "  'trade_login_fail_rate_30',\n",
       "  'trade_login_fail_rate_360',\n",
       "  'trade_login_fail_rate_7',\n",
       "  'trade_login_rate_1',\n",
       "  'trade_login_rate_15',\n",
       "  'trade_login_rate_3',\n",
       "  'trade_login_rate_30',\n",
       "  'trade_login_rate_360',\n",
       "  'trade_login_rate_7',\n",
       "  'trade_login_success_rate_1',\n",
       "  'trade_login_success_rate_15',\n",
       "  'trade_login_success_rate_3',\n",
       "  'trade_login_success_rate_30',\n",
       "  'trade_login_success_rate_360',\n",
       "  'trade_login_success_rate_7',\n",
       "  'trade_times_1',\n",
       "  'trade_times_15',\n",
       "  'trade_times_3',\n",
       "  'trade_times_30',\n",
       "  'trade_times_360',\n",
       "  'trade_times_7'],\n",
       " 'recent_login_detail': ['timelong_login_0',\n",
       "  'timelong_login_1',\n",
       "  'timelong_login_2',\n",
       "  'log_from_login_0',\n",
       "  'log_from_login_1',\n",
       "  'log_from_login_2',\n",
       "  'city_login_0',\n",
       "  'city_login_1',\n",
       "  'city_login_2',\n",
       "  'result_login_0',\n",
       "  'result_login_1',\n",
       "  'result_login_2',\n",
       "  'type_login_0',\n",
       "  'type_login_1',\n",
       "  'type_login_2',\n",
       "  'is_scan_login_0',\n",
       "  'is_scan_login_1',\n",
       "  'is_scan_login_2',\n",
       "  'month_login_0',\n",
       "  'month_login_1',\n",
       "  'month_login_2',\n",
       "  'day_login_0',\n",
       "  'day_login_1',\n",
       "  'day_login_2',\n",
       "  'weekday_login_0',\n",
       "  'weekday_login_1',\n",
       "  'weekday_login_2',\n",
       "  'hour_login_0',\n",
       "  'hour_login_1',\n",
       "  'hour_login_2',\n",
       "  'day_cycle_login_0',\n",
       "  'day_cycle_login_1',\n",
       "  'day_cycle_login_2',\n",
       "  'weekday_cycle_login_0',\n",
       "  'weekday_cycle_login_1',\n",
       "  'weekday_cycle_login_2',\n",
       "  'hour_cycle_login_0',\n",
       "  'hour_cycle_login_1',\n",
       "  'hour_cycle_login_2',\n",
       "  'recent_login_number'],\n",
       " 'trade_and_recent_login_comparing': ['device_comparing_login_1',\n",
       "  'device_comparing_login_2',\n",
       "  'ip_comparing_login_1',\n",
       "  'ip_comparing_login_2',\n",
       "  'city_comparing_login_1',\n",
       "  'city_comparing_login_2',\n",
       "  'log_from_comparing_login_1',\n",
       "  'log_from_comparing_login_2',\n",
       "  'result_comparing_login_1',\n",
       "  'result_comparing_login_2',\n",
       "  'type_comparing_login_1',\n",
       "  'type_comparing_login_2',\n",
       "  'login_distance_0',\n",
       "  'login_distance_1',\n",
       "  'login_distance_2'],\n",
       " 'trade_detail_feature': ['month',\n",
       "  'day',\n",
       "  'weekday',\n",
       "  'hour',\n",
       "  'day_cycle',\n",
       "  'weekday_cycle',\n",
       "  'hour_cycle']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =   (config.feature_dict['trade_detail_feature']+\n",
    "              config.feature_dict['recent_login_detail']+\n",
    "              config.feature_dict['trade_and_recent_login_comparing']+\n",
    "              config.feature_dict['login_trade_hist_stats'])\n",
    "feature_sequence_list = []\n",
    "for feature in features:\n",
    "    feature_sequence_list.append(pd.read_pickle(feature_path+feature+'.pkl').reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(feature_sequence_list)):\n",
    "    if feature_sequence_list[i].shape != feature_sequence_list[0].shape:\n",
    "        print(features[i],feature_sequence_list[i].shape)\n",
    "trade_tt_mat = np.hstack(feature_sequence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation via GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model define\n",
    "\n",
    "def f_beta_01(preds, train_data):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(labels, preds > 0.5,0.1),True\n",
    "\n",
    "    \n",
    "#for binary\n",
    "def runLGBM(train_X, train_y, test_X, test_y=None, feature_names=None,\n",
    "           seed_val=0, num_rounds=10000,watch_dict = None,max_bin=50000,\n",
    "           num_leaves=16,early_stop=64,verbose=True,eta=0.1,\n",
    "           bagging_fraction = 0.75 , feature_fraction = 0.75,feval = None,metric = 'binary_logloss',\n",
    "           train_sample_weight = None):\n",
    "    \n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': eta,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': verbose,\n",
    "        'is_unbalance':False\n",
    "    }\n",
    "    \n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    #plst = list(param.items())\n",
    "    lgbtrain = lgb.Dataset(train_X, label=train_y,max_bin=max_bin,feature_name=feature_names,weight =train_sample_weight)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgbtest = lgb.Dataset(test_X, label=test_y,max_bin=max_bin,feature_name=feature_names)\n",
    "        watchlist = [lgbtrain,lgbtest]\n",
    "        watchlist_name=['train','test']\n",
    "        model = lgb.train(params, lgbtrain, num_rounds, watchlist,watchlist_name, early_stopping_rounds=early_stop,\\\n",
    "                         evals_result = watch_dict,verbose_eval=verbose,feval = feval)\n",
    "    else:\n",
    "        #lgbtest = lgb.Dataset(test_X,feature_name=feature_names)\n",
    "        model = lgb.train(params, lgbtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_tuple_list = config.single_module_validation_indice_set\n",
    "train_labels = pd.read_pickle(data_path+'trade_train_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.93919\ttest's auc: 0.922661\n",
      "[200]\ttrain's auc: 0.97702\ttest's auc: 0.959978\n",
      "[300]\ttrain's auc: 0.992494\ttest's auc: 0.967505\n",
      "[400]\ttrain's auc: 0.997036\ttest's auc: 0.967873\n",
      "[500]\ttrain's auc: 0.998632\ttest's auc: 0.967099\n",
      "Early stopping, best iteration is:\n",
      "[411]\ttrain's auc: 0.997187\ttest's auc: 0.968222\n",
      "f_beta score for the turn 1 is 0.823529411765\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.95801\ttest's auc: 0.846613\n",
      "[200]\ttrain's auc: 0.983573\ttest's auc: 0.886538\n",
      "[300]\ttrain's auc: 0.99384\ttest's auc: 0.901938\n",
      "[400]\ttrain's auc: 0.998148\ttest's auc: 0.909854\n",
      "[500]\ttrain's auc: 0.999164\ttest's auc: 0.912912\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttrain's auc: 0.999138\ttest's auc: 0.91367\n",
      "f_beta score for the turn 2 is 0.36685584563\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.949772\ttest's auc: 0.919627\n",
      "[200]\ttrain's auc: 0.980322\ttest's auc: 0.941927\n",
      "[300]\ttrain's auc: 0.99334\ttest's auc: 0.949981\n",
      "[400]\ttrain's auc: 0.99813\ttest's auc: 0.954617\n",
      "[500]\ttrain's auc: 0.999317\ttest's auc: 0.953799\n",
      "Early stopping, best iteration is:\n",
      "[410]\ttrain's auc: 0.998274\ttest's auc: 0.955372\n",
      "f_beta score for the turn 3 is 0.793962738778\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.951951\ttest's auc: 0.881428\n",
      "[200]\ttrain's auc: 0.975765\ttest's auc: 0.922981\n",
      "[300]\ttrain's auc: 0.993464\ttest's auc: 0.936066\n",
      "[400]\ttrain's auc: 0.998108\ttest's auc: 0.939566\n",
      "[500]\ttrain's auc: 0.999176\ttest's auc: 0.942799\n",
      "[600]\ttrain's auc: 0.99972\ttest's auc: 0.941171\n",
      "Early stopping, best iteration is:\n",
      "[513]\ttrain's auc: 0.999263\ttest's auc: 0.943463\n",
      "f_beta score for the turn 4 is 0.408135775862\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.924723\ttest's auc: 0.914984\n",
      "[200]\ttrain's auc: 0.977686\ttest's auc: 0.949051\n",
      "[300]\ttrain's auc: 0.992546\ttest's auc: 0.962595\n",
      "[400]\ttrain's auc: 0.998045\ttest's auc: 0.962906\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttrain's auc: 0.996713\ttest's auc: 0.963973\n",
      "f_beta score for the turn 5 is 0.788201728623\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.955394\ttest's auc: 0.878846\n",
      "[200]\ttrain's auc: 0.978893\ttest's auc: 0.908099\n",
      "[300]\ttrain's auc: 0.993762\ttest's auc: 0.930404\n",
      "[400]\ttrain's auc: 0.99786\ttest's auc: 0.936121\n",
      "[500]\ttrain's auc: 0.998938\ttest's auc: 0.937826\n",
      "Early stopping, best iteration is:\n",
      "[485]\ttrain's auc: 0.998825\ttest's auc: 0.938816\n",
      "f_beta score for the turn 6 is 0.623090481786\n",
      "The mean of the cv_scores is: 0.633962663741\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_mat[train_indice], trade_tt_mat[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = None)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试使用取消使用-10对np.nan的填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.945878\ttest's auc: 0.931352\n",
      "[200]\ttrain's auc: 0.976898\ttest's auc: 0.959542\n",
      "[300]\ttrain's auc: 0.992755\ttest's auc: 0.96718\n",
      "[400]\ttrain's auc: 0.996926\ttest's auc: 0.968233\n",
      "Early stopping, best iteration is:\n",
      "[358]\ttrain's auc: 0.995888\ttest's auc: 0.968809\n",
      "f_beta score for the turn 1 is 0.829843625762\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.959529\ttest's auc: 0.85979\n",
      "[200]\ttrain's auc: 0.98352\ttest's auc: 0.884438\n",
      "[300]\ttrain's auc: 0.994636\ttest's auc: 0.903044\n",
      "[400]\ttrain's auc: 0.998366\ttest's auc: 0.912637\n",
      "[500]\ttrain's auc: 0.999278\ttest's auc: 0.916982\n",
      "[600]\ttrain's auc: 0.999688\ttest's auc: 0.917708\n",
      "[700]\ttrain's auc: 0.999871\ttest's auc: 0.918058\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttrain's auc: 0.999822\ttest's auc: 0.919654\n",
      "f_beta score for the turn 2 is 0.37537746806\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.958854\ttest's auc: 0.923541\n",
      "[200]\ttrain's auc: 0.98028\ttest's auc: 0.940249\n",
      "[300]\ttrain's auc: 0.99389\ttest's auc: 0.947771\n",
      "[400]\ttrain's auc: 0.998418\ttest's auc: 0.952949\n",
      "[500]\ttrain's auc: 0.999452\ttest's auc: 0.954645\n",
      "Early stopping, best iteration is:\n",
      "[497]\ttrain's auc: 0.999424\ttest's auc: 0.954798\n",
      "f_beta score for the turn 3 is 0.777455986586\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.951197\ttest's auc: 0.884231\n",
      "[200]\ttrain's auc: 0.97679\ttest's auc: 0.925408\n",
      "[300]\ttrain's auc: 0.994986\ttest's auc: 0.939816\n",
      "[400]\ttrain's auc: 0.998432\ttest's auc: 0.943941\n",
      "[500]\ttrain's auc: 0.999262\ttest's auc: 0.945976\n",
      "[600]\ttrain's auc: 0.999677\ttest's auc: 0.945849\n",
      "Early stopping, best iteration is:\n",
      "[558]\ttrain's auc: 0.999522\ttest's auc: 0.947064\n",
      "f_beta score for the turn 4 is 0.473622508792\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.931185\ttest's auc: 0.921351\n",
      "[200]\ttrain's auc: 0.977036\ttest's auc: 0.945034\n",
      "[300]\ttrain's auc: 0.994067\ttest's auc: 0.958571\n",
      "[400]\ttrain's auc: 0.998243\ttest's auc: 0.96248\n",
      "[500]\ttrain's auc: 0.999295\ttest's auc: 0.961497\n",
      "Early stopping, best iteration is:\n",
      "[401]\ttrain's auc: 0.998265\ttest's auc: 0.962576\n",
      "f_beta score for the turn 5 is 0.771251153814\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.953117\ttest's auc: 0.872014\n",
      "[200]\ttrain's auc: 0.980043\ttest's auc: 0.904679\n",
      "[300]\ttrain's auc: 0.99409\ttest's auc: 0.926168\n",
      "[400]\ttrain's auc: 0.998065\ttest's auc: 0.934178\n",
      "[500]\ttrain's auc: 0.999109\ttest's auc: 0.936513\n",
      "Early stopping, best iteration is:\n",
      "[481]\ttrain's auc: 0.999001\ttest's auc: 0.937464\n",
      "f_beta score for the turn 6 is 0.56374853114\n",
      "The mean of the cv_scores is: 0.631883212359\n"
     ]
    }
   ],
   "source": [
    "trade_tt_mat_with_NA = trade_tt_mat\n",
    "trade_tt_mat_with_NA[trade_tt_mat_with_NA==-10]=np.nan\n",
    "\n",
    "\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_mat_with_NA[train_indice], trade_tt_mat_with_NA[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = None)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check basic model importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_total = np.zeros(176)\n",
    "for model in models:\n",
    "    feature_importance_total+=model.feature_importance('gain')\n",
    "sorted_feature_importacne = sorted(zip(features,feature_importance_total),key = lambda x : x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('login_distance_0', 59223.424537617204),\n",
       " ('type_login_0', 23794.921317119552),\n",
       " ('login_distance_1', 20870.283181648574),\n",
       " ('trade_login_success_rate_1', 19317.561688541751),\n",
       " ('trade_times_1', 18997.744010064289),\n",
       " ('trade_login_rate_1', 17805.561171391761),\n",
       " ('trade_times_360', 17048.483074551063),\n",
       " ('login_success_rate_360', 16021.519821167383),\n",
       " ('login_success_rate_30', 14350.744728325808),\n",
       " ('timelong_std_1', 13696.724039177499),\n",
       " ('timelong_min_30', 13296.791676022744),\n",
       " ('login_success_times_360', 13190.676552805899),\n",
       " ('timelong_min_15', 11219.898247384339),\n",
       " ('type_login_1', 10520.893633008511),\n",
       " ('hour_login_2', 9929.3690999721111),\n",
       " ('hour_login_0', 9619.492702716565),\n",
       " ('timelong_max_1', 9449.6609686912961),\n",
       " ('login_distance_2', 9325.3054719801185),\n",
       " ('timelong_std_3', 8606.6309386399371),\n",
       " ('timelong_med_360', 7642.8078753582231),\n",
       " ('device_comparing_login_1', 6856.0971432348952),\n",
       " ('login_times_360', 6819.9994565205343),\n",
       " ('trade_login_fail_rate_360', 6716.3358915877561),\n",
       " ('city_login_0', 6383.0077280209516),\n",
       " ('hour', 6329.4551675193088),\n",
       " ('city_login_2', 5807.741001589111),\n",
       " ('timelong_login_0', 5722.0372336637647),\n",
       " ('hour_cycle_login_0', 5569.2917775186097),\n",
       " ('timelong_mean_360', 5334.5325461456214),\n",
       " ('hour_login_1', 5183.3659230338817),\n",
       " ('city_login_1', 5140.3167945058603),\n",
       " ('after_fail_max_30', 4697.4334282606351),\n",
       " ('timelong_std_15', 4639.8900926489732),\n",
       " ('type_login_2', 4627.8095553592657),\n",
       " ('timelong_min_360', 4520.8377864547865),\n",
       " ('timelong_std_30', 4381.8818439503902),\n",
       " ('timelong_std_360', 4363.8921636593695),\n",
       " ('timelong_med_1', 4297.2851163484938),\n",
       " ('timelong_med_3', 4153.5617690859563),\n",
       " ('result_login_1', 4025.1418485041445),\n",
       " ('hour_cycle', 3933.1241523646422),\n",
       " ('timelong_std_7', 3821.2645222975261),\n",
       " ('timelong_max_3', 3798.965542637965),\n",
       " ('timelong_min_7', 3735.5184832427467),\n",
       " ('login_success_times_30', 3709.1841211786477),\n",
       " ('timelong_max_360', 3697.9211059423669),\n",
       " ('timelong_mean_3', 3689.9786015413624),\n",
       " ('device_comparing_login_2', 3644.2404257546309),\n",
       " ('after_fail_max_360', 3546.3189782596423),\n",
       " ('hour_cycle_login_2', 3418.6451367389295),\n",
       " ('timelong_mean_7', 3416.8656744744189),\n",
       " ('timelong_min_3', 3394.8413479128544),\n",
       " ('timelong_mean_1', 3356.5552715164108),\n",
       " ('month_login_1', 3206.1933914805195),\n",
       " ('timelong_login_1', 3194.7920231686176),\n",
       " ('timelong_login_2', 3175.9122853895497),\n",
       " ('timelong_med_7', 3160.9274613764933),\n",
       " ('hour_cycle_login_1', 2986.4558837367117),\n",
       " ('month_login_2', 2959.3990900182121),\n",
       " ('day', 2803.8840056777035),\n",
       " ('result_login_2', 2764.9226763547249),\n",
       " ('trade_times_3', 2676.4627718401189),\n",
       " ('trade_login_fail_rate_30', 2576.1357078210103),\n",
       " ('trade_login_rate_360', 2526.8214535864035),\n",
       " ('day_cycle', 2507.1670510423514),\n",
       " ('timelong_max_30', 2463.1865760132137),\n",
       " ('timelong_min_1', 2426.1958553539744),\n",
       " ('day_login_2', 2420.5363769569954),\n",
       " ('city_comparing_login_2', 2403.0219716937481),\n",
       " ('timelong_mean_15', 2397.7678441050712),\n",
       " ('timelong_mean_30', 2318.3972246557055),\n",
       " ('login_success_times_7', 2289.6185758611746),\n",
       " ('day_cycle_login_1', 2205.8139718108364),\n",
       " ('day_login_1', 2076.3674085001412),\n",
       " ('timelong_max_7', 2068.1888147860291),\n",
       " ('after_fail_std_360', 2061.6177598541744),\n",
       " ('ip_comparing_login_1', 2045.6245401462456),\n",
       " ('day_login_0', 2041.1948789365363),\n",
       " ('day_cycle_login_2', 1832.8835885437854),\n",
       " ('timelong_med_30', 1796.8242336079388),\n",
       " ('login_success_times_15', 1642.8520266699397),\n",
       " ('month', 1638.6872990398574),\n",
       " ('trade_login_success_rate_360', 1636.1315051952974),\n",
       " ('weekday_cycle_login_2', 1611.4702476556308),\n",
       " ('trade_login_fail_rate_15', 1608.4794050992091),\n",
       " ('login_fail_times_360', 1549.6564510886492),\n",
       " ('timelong_med_15', 1534.2072948539992),\n",
       " ('login_times_30', 1528.8422885822188),\n",
       " ('trade_login_success_rate_3', 1522.7326568720769),\n",
       " ('trade_login_rate_3', 1469.580730875356),\n",
       " ('timelong_max_15', 1389.2139271024951),\n",
       " ('trade_login_rate_7', 1357.1238412273653),\n",
       " ('trade_login_success_rate_7', 1310.4532274375811),\n",
       " ('day_cycle_login_0', 1294.0961186999468),\n",
       " ('login_success_times_1', 1190.8909981900188),\n",
       " ('weekday_cycle_login_0', 1161.3546890841167),\n",
       " ('after_fail_mean_360', 1095.9237036080842),\n",
       " ('weekday', 1093.8792652878446),\n",
       " ('after_fail_min_30', 1084.0866744348025),\n",
       " ('trade_times_7', 1076.3002033674679),\n",
       " ('after_fail_mean_7', 1074.4650723947136),\n",
       " ('trade_times_30', 1054.5891063458553),\n",
       " ('after_fail_min_7', 1046.2366106180823),\n",
       " ('weekday_cycle', 1044.3666459636381),\n",
       " ('after_fail_med_360', 1022.1155332552635),\n",
       " ('result_comparing_login_1', 998.80430272252829),\n",
       " ('login_times_7', 979.02612963401589),\n",
       " ('weekday_login_2', 930.071539150592),\n",
       " ('login_times_15', 914.72618712139933),\n",
       " ('after_fail_min_360', 891.13273848767426),\n",
       " ('login_times_3', 870.22894894892124),\n",
       " ('result_comparing_login_2', 778.80720754579465),\n",
       " ('trade_login_rate_30', 777.49928401279976),\n",
       " ('after_fail_max_7', 776.96750483031371),\n",
       " ('login_fail_times_15', 754.35327272076165),\n",
       " ('login_times_1', 743.92768744050852),\n",
       " ('month_login_0', 729.39651683583372),\n",
       " ('login_success_times_3', 719.81927223706987),\n",
       " ('after_fail_mean_30', 711.32023952011741),\n",
       " ('weekday_login_0', 692.58884875340448),\n",
       " ('trade_times_15', 682.29981128289751),\n",
       " ('ip_comparing_login_2', 660.33213898099802),\n",
       " ('weekday_cycle_login_1', 658.98071432354584),\n",
       " ('trade_login_success_rate_30', 634.6870929827096),\n",
       " ('weekday_login_1', 599.24135896001019),\n",
       " ('log_from_login_2', 583.37063189257503),\n",
       " ('result_login_0', 569.8055065877295),\n",
       " ('trade_login_rate_15', 520.57894078872903),\n",
       " ('login_fail_times_30', 519.67751237668278),\n",
       " ('login_success_rate_15', 467.17317179891148),\n",
       " ('log_from_login_0', 434.19380830824724),\n",
       " ('after_fail_max_15', 410.90726401703807),\n",
       " ('trade_login_success_rate_15', 372.33032050804428),\n",
       " ('after_fail_med_7', 357.18458270393472),\n",
       " ('log_from_login_1', 326.08018337954866),\n",
       " ('city_comparing_login_1', 303.79915405473719),\n",
       " ('after_fail_med_30', 281.35649975748959),\n",
       " ('after_fail_std_7', 265.50254826974214),\n",
       " ('trade_login_fail_rate_1', 264.21406211633672),\n",
       " ('after_fail_min_15', 234.28130262694884),\n",
       " ('log_from_comparing_login_1', 220.05216764581499),\n",
       " ('login_success_rate_7', 213.01875027522345),\n",
       " ('after_fail_max_3', 208.20130939366942),\n",
       " ('after_fail_min_3', 193.70211701048862),\n",
       " ('after_fail_mean_3', 192.74453291581614),\n",
       " ('after_fail_mean_15', 152.40463579968093),\n",
       " ('after_fail_std_30', 137.58340182169536),\n",
       " ('after_fail_med_15', 133.79176215401239),\n",
       " ('multiple_fails_15', 125.30510024367992),\n",
       " ('log_from_comparing_login_2', 113.00244112784796),\n",
       " ('after_fail_max_1', 99.406500467883404),\n",
       " ('login_success_rate_1', 95.796870979931754),\n",
       " ('type_comparing_login_2', 89.462725560086341),\n",
       " ('trade_login_fail_rate_3', 84.796618720364137),\n",
       " ('login_fail_times_7', 83.292088894547305),\n",
       " ('trade_login_fail_rate_7', 72.166781646995119),\n",
       " ('after_fail_med_1', 62.677844870931352),\n",
       " ('login_success_rate_3', 59.776491641218399),\n",
       " ('after_fail_med_3', 57.385937714761539),\n",
       " ('multiple_fails_7', 48.678430900627973),\n",
       " ('login_fail_times_3', 45.893255414037334),\n",
       " ('multiple_fails_360', 38.171151354909654),\n",
       " ('after_fail_mean_1', 36.893835219216456),\n",
       " ('after_fail_std_15', 27.834273655181221),\n",
       " ('multiple_fails_30', 12.272361447771022),\n",
       " ('is_scan_login_0', 10.670598113759638),\n",
       " ('type_comparing_login_1', 8.8616386831633598),\n",
       " ('login_fail_times_1', 8.3262908125896153),\n",
       " ('is_scan_login_1', 0.0),\n",
       " ('is_scan_login_2', 0.0),\n",
       " ('recent_login_number', 0.0),\n",
       " ('after_fail_min_1', 0.0),\n",
       " ('after_fail_std_1', 0.0),\n",
       " ('after_fail_std_3', 0.0),\n",
       " ('multiple_fails_1', 0.0),\n",
       " ('multiple_fails_3', 0.0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_feature_importacne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 176 artists>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3793c50128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "all_importance = [x[1] for x in sorted_feature_importacne]\n",
    "x = pd.Series(all_importance).sort_values(ascending = False).cumsum()\n",
    "plt.bar(range(len(x)),x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以考虑在100~120处进行特征截断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加feval作为参考量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.945878\ttrain's fbeta_score_01: 0.945993\ttest's auc: 0.931352\ttest's fbeta_score_01: 0.834592\n",
      "[200]\ttrain's auc: 0.976898\ttrain's fbeta_score_01: 0.943116\ttest's auc: 0.959542\ttest's fbeta_score_01: 0.834041\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttrain's auc: 0.957666\ttrain's fbeta_score_01: 0.948297\ttest's auc: 0.946622\ttest's fbeta_score_01: 0.854527\n",
      "f_beta score for the turn 1 is 0.854527086753\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.959529\ttrain's fbeta_score_01: 0.931692\ttest's auc: 0.85979\ttest's fbeta_score_01: 0.143772\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttrain's auc: 0.943696\ttrain's fbeta_score_01: 0.893504\ttest's auc: 0.807732\ttest's fbeta_score_01: 0.212073\n",
      "f_beta score for the turn 2 is 0.212073490814\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.958854\ttrain's fbeta_score_01: 0.96336\ttest's auc: 0.923541\ttest's fbeta_score_01: 0.820835\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttrain's auc: 0.940206\ttrain's fbeta_score_01: 0.953274\ttest's auc: 0.901091\ttest's fbeta_score_01: 0.874688\n",
      "f_beta score for the turn 3 is 0.874688361107\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.951197\ttrain's fbeta_score_01: 0.934715\ttest's auc: 0.884231\ttest's fbeta_score_01: 0.181655\n",
      "[200]\ttrain's auc: 0.97679\ttrain's fbeta_score_01: 0.946596\ttest's auc: 0.925408\ttest's fbeta_score_01: 0.4566\n",
      "[300]\ttrain's auc: 0.994986\ttrain's fbeta_score_01: 0.954901\ttest's auc: 0.939816\ttest's fbeta_score_01: 0.469456\n",
      "Early stopping, best iteration is:\n",
      "[264]\ttrain's auc: 0.989726\ttrain's fbeta_score_01: 0.951649\ttest's auc: 0.935674\ttest's fbeta_score_01: 0.502845\n",
      "f_beta score for the turn 4 is 0.502844950213\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.931185\ttrain's fbeta_score_01: 0.937633\ttest's auc: 0.921351\ttest's fbeta_score_01: 0.795944\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttrain's auc: 0.91512\ttrain's fbeta_score_01: 0.949292\ttest's auc: 0.896685\ttest's fbeta_score_01: 0.77437\n",
      "f_beta score for the turn 5 is 0.774370208105\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.953117\ttrain's fbeta_score_01: 0.924874\ttest's auc: 0.872014\ttest's fbeta_score_01: 0.47008\n",
      "[200]\ttrain's auc: 0.980043\ttrain's fbeta_score_01: 0.938996\ttest's auc: 0.904679\ttest's fbeta_score_01: 0.504083\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttrain's auc: 0.964515\ttrain's fbeta_score_01: 0.926207\ttest's auc: 0.887336\ttest's fbeta_score_01: 0.651995\n",
      "f_beta score for the turn 6 is 0.651995305164\n",
      "The mean of the cv_scores is: 0.645083233693\n"
     ]
    }
   ],
   "source": [
    "trade_tt_mat_with_NA = trade_tt_mat\n",
    "trade_tt_mat_with_NA[trade_tt_mat_with_NA==-10]=np.nan\n",
    "\n",
    "\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_mat_with_NA[train_indice], trade_tt_mat_with_NA[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = f_beta_01)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 or 120 top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_100_features =  [x[0] for x in sorted_feature_importacne][0:100]\n",
    "top_120_features = [x[0] for x in sorted_feature_importacne][0:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_feature_ori_index = [features.index(x) for x in top_100_features]\n",
    "top_120_feature_ori_index = [features.index(x) for x in top_120_features]\n",
    "\n",
    "trade_tt_mat_top_100 = trade_tt_mat[:,top_100_feature_ori_index]\n",
    "trade_tt_mat_top_120 = trade_tt_mat[:,top_120_feature_ori_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.945752\ttest's auc: 0.930972\n",
      "[200]\ttrain's auc: 0.975861\ttest's auc: 0.962274\n",
      "[300]\ttrain's auc: 0.991401\ttest's auc: 0.968582\n",
      "[400]\ttrain's auc: 0.996859\ttest's auc: 0.970153\n",
      "Early stopping, best iteration is:\n",
      "[369]\ttrain's auc: 0.995713\ttest's auc: 0.970659\n",
      "f_beta score for the turn 1 is 0.841743749428\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.960797\ttest's auc: 0.849681\n",
      "[200]\ttrain's auc: 0.983036\ttest's auc: 0.887895\n",
      "[300]\ttrain's auc: 0.994592\ttest's auc: 0.898921\n",
      "[400]\ttrain's auc: 0.99814\ttest's auc: 0.905889\n",
      "[500]\ttrain's auc: 0.999076\ttest's auc: 0.910468\n",
      "[600]\ttrain's auc: 0.999713\ttest's auc: 0.911916\n",
      "[700]\ttrain's auc: 0.999884\ttest's auc: 0.912116\n",
      "Early stopping, best iteration is:\n",
      "[650]\ttrain's auc: 0.999824\ttest's auc: 0.913811\n",
      "f_beta score for the turn 2 is 0.36685584563\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.953842\ttest's auc: 0.926966\n",
      "[200]\ttrain's auc: 0.981922\ttest's auc: 0.94174\n",
      "[300]\ttrain's auc: 0.993875\ttest's auc: 0.949881\n",
      "[400]\ttrain's auc: 0.997631\ttest's auc: 0.951\n",
      "[500]\ttrain's auc: 0.999372\ttest's auc: 0.950958\n",
      "Early stopping, best iteration is:\n",
      "[463]\ttrain's auc: 0.999073\ttest's auc: 0.95187\n",
      "f_beta score for the turn 3 is 0.774379043207\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.954414\ttest's auc: 0.891421\n",
      "[200]\ttrain's auc: 0.974353\ttest's auc: 0.923372\n",
      "[300]\ttrain's auc: 0.994482\ttest's auc: 0.941607\n",
      "[400]\ttrain's auc: 0.998544\ttest's auc: 0.942226\n",
      "[500]\ttrain's auc: 0.99926\ttest's auc: 0.943092\n",
      "[600]\ttrain's auc: 0.999729\ttest's auc: 0.94215\n",
      "Early stopping, best iteration is:\n",
      "[560]\ttrain's auc: 0.999607\ttest's auc: 0.943401\n",
      "f_beta score for the turn 4 is 0.475359911406\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.933873\ttest's auc: 0.916948\n",
      "[200]\ttrain's auc: 0.976411\ttest's auc: 0.946733\n",
      "[300]\ttrain's auc: 0.994446\ttest's auc: 0.958696\n",
      "[400]\ttrain's auc: 0.998241\ttest's auc: 0.962679\n",
      "[500]\ttrain's auc: 0.999313\ttest's auc: 0.962886\n",
      "[600]\ttrain's auc: 0.999697\ttest's auc: 0.962071\n",
      "Early stopping, best iteration is:\n",
      "[545]\ttrain's auc: 0.99952\ttest's auc: 0.96313\n",
      "f_beta score for the turn 5 is 0.790047432804\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.957462\ttest's auc: 0.876179\n",
      "[200]\ttrain's auc: 0.981717\ttest's auc: 0.909173\n",
      "[300]\ttrain's auc: 0.994129\ttest's auc: 0.924887\n",
      "[400]\ttrain's auc: 0.997742\ttest's auc: 0.930968\n",
      "[500]\ttrain's auc: 0.998941\ttest's auc: 0.935096\n",
      "[600]\ttrain's auc: 0.999552\ttest's auc: 0.938953\n",
      "[700]\ttrain's auc: 0.999781\ttest's auc: 0.938798\n",
      "Early stopping, best iteration is:\n",
      "[630]\ttrain's auc: 0.999634\ttest's auc: 0.939859\n",
      "f_beta score for the turn 6 is 0.569159836066\n",
      "The mean of the cv_scores is:\n",
      "0.636257636423\n"
     ]
    }
   ],
   "source": [
    "#top 100 features\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_mat_top_100[train_indice], trade_tt_mat_top_100[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=top_100_features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = None)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.945648\ttest's auc: 0.931387\n",
      "[200]\ttrain's auc: 0.976171\ttest's auc: 0.959514\n",
      "[300]\ttrain's auc: 0.99255\ttest's auc: 0.967698\n",
      "[400]\ttrain's auc: 0.997048\ttest's auc: 0.969833\n",
      "Early stopping, best iteration is:\n",
      "[369]\ttrain's auc: 0.996306\ttest's auc: 0.970137\n",
      "f_beta score for the turn 1 is 0.843187881918\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.960166\ttest's auc: 0.853897\n",
      "[200]\ttrain's auc: 0.982984\ttest's auc: 0.881746\n",
      "[300]\ttrain's auc: 0.994375\ttest's auc: 0.899809\n",
      "[400]\ttrain's auc: 0.997928\ttest's auc: 0.90811\n",
      "[500]\ttrain's auc: 0.998999\ttest's auc: 0.912305\n",
      "Early stopping, best iteration is:\n",
      "[445]\ttrain's auc: 0.998643\ttest's auc: 0.913362\n",
      "f_beta score for the turn 2 is 0.369062119367\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.952487\ttest's auc: 0.922335\n",
      "[200]\ttrain's auc: 0.981645\ttest's auc: 0.93912\n",
      "[300]\ttrain's auc: 0.994653\ttest's auc: 0.947541\n",
      "[400]\ttrain's auc: 0.998009\ttest's auc: 0.950856\n",
      "[500]\ttrain's auc: 0.999334\ttest's auc: 0.952333\n",
      "[600]\ttrain's auc: 0.999696\ttest's auc: 0.953539\n",
      "Early stopping, best iteration is:\n",
      "[585]\ttrain's auc: 0.999673\ttest's auc: 0.953868\n",
      "f_beta score for the turn 3 is 0.750819911085\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.950849\ttest's auc: 0.88267\n",
      "[200]\ttrain's auc: 0.973561\ttest's auc: 0.922637\n",
      "[300]\ttrain's auc: 0.994353\ttest's auc: 0.937572\n",
      "[400]\ttrain's auc: 0.998444\ttest's auc: 0.942353\n",
      "[500]\ttrain's auc: 0.999312\ttest's auc: 0.942846\n",
      "Early stopping, best iteration is:\n",
      "[483]\ttrain's auc: 0.999221\ttest's auc: 0.943443\n",
      "f_beta score for the turn 4 is 0.473622508792\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.939676\ttest's auc: 0.92017\n",
      "[200]\ttrain's auc: 0.977714\ttest's auc: 0.945146\n",
      "[300]\ttrain's auc: 0.993838\ttest's auc: 0.955796\n",
      "[400]\ttrain's auc: 0.99837\ttest's auc: 0.959143\n",
      "[500]\ttrain's auc: 0.999373\ttest's auc: 0.960245\n",
      "[600]\ttrain's auc: 0.99972\ttest's auc: 0.959124\n",
      "Early stopping, best iteration is:\n",
      "[544]\ttrain's auc: 0.999551\ttest's auc: 0.960345\n",
      "f_beta score for the turn 5 is 0.76884668904\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.955419\ttest's auc: 0.871293\n",
      "[200]\ttrain's auc: 0.9801\ttest's auc: 0.906197\n",
      "[300]\ttrain's auc: 0.993692\ttest's auc: 0.923336\n",
      "[400]\ttrain's auc: 0.997803\ttest's auc: 0.92697\n",
      "[500]\ttrain's auc: 0.999003\ttest's auc: 0.929528\n",
      "[600]\ttrain's auc: 0.999564\ttest's auc: 0.934425\n",
      "[700]\ttrain's auc: 0.999802\ttest's auc: 0.935313\n",
      "Early stopping, best iteration is:\n",
      "[661]\ttrain's auc: 0.99972\ttest's auc: 0.936575\n",
      "f_beta score for the turn 6 is 0.532463928968\n",
      "The mean of the cv_scores is:\n",
      "0.623000506528\n"
     ]
    }
   ],
   "source": [
    "#top 120 features\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_mat_top_120[train_indice], trade_tt_mat_top_120[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=top_120_features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = None)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_features = {}\n",
    "config.model_features['moded_C1_top100'] = top_100_features\n",
    "config.model_features['moded_C1_top100'] = top_120_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data_path', 'feature_dict', 'feature_path', 'model_features', 'result_path', 'single_module_validation_indice_set', 'trade_train_size', 'train_2_6_index']\n"
     ]
    }
   ],
   "source": [
    "print(dir(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(config,'config_py3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if new features are performed PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_features =   (config.feature_dict['trade_detail_feature']+\n",
    "              config.feature_dict['recent_login_detail']+\n",
    "              config.feature_dict['trade_and_recent_login_comparing'])\n",
    "pca_features = config.feature_dict['login_trade_hist_stats']\n",
    "ori_feature_sequence_list = []\n",
    "pca_feature_sequence_list = []\n",
    "for feature in ori_features:\n",
    "    ori_feature_sequence_list.append(pd.read_pickle(feature_path+feature+'.pkl').reshape(-1,1))\n",
    "    \n",
    "for feature in pca_features:\n",
    "    pca_feature_sequence_list.append(pd.read_pickle(feature_path+feature+'.pkl').reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trade_tt_ori = np.hstack(ori_feature_sequence_list)\n",
    "trade_tt_to_be_pca = np.hstack(pca_feature_sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the na values to be mean\n",
    "trade_tt_to_be_pca[trade_tt_to_be_pca ==-10] = np.nan\n",
    "trade_tt_to_be_pca[trade_tt_to_be_pca ==-np.inf] = -10\n",
    "for i in range(trade_tt_to_be_pca.shape[1]):\n",
    "    trade_tt_to_be_pca[np.isnan(trade_tt_to_be_pca[:,i]) ,i] = pd.Series(trade_tt_to_be_pca[:,i]).dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(trade_tt_to_be_pca.shape[1]):\n",
    "    trade_tt_to_be_pca[np.isnan(trade_tt_to_be_pca[:,i]) ,i] = pd.Series(trade_tt_to_be_pca[:,i]).dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try pca with all to find out explained_variance_ratio_ \n",
    "all_pca = PCA(whiten = True)\n",
    "all_pca.fit(trade_tt_to_be_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99987614009848413"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(all_pca.explained_variance_ratio_[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150594, 20)\n"
     ]
    }
   ],
   "source": [
    "#use 1~20 for the resulting\n",
    "apply_pac = PCA(n_components = 20,whiten = True)\n",
    "trade_tt_type_C_pca = apply_pac.fit_transform(trade_tt_to_be_pca)\n",
    "print(trade_tt_type_C_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trade_tt_mat = np.hstack([trade_tt_ori,trade_tt_type_C_pca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_c_pca_feature_list = ['type_c_feature_pca_'+str(i) for i in range(20)] \n",
    "features = ori_features+type_c_pca_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.944916\ttest's auc: 0.933217\n",
      "[200]\ttrain's auc: 0.976134\ttest's auc: 0.961169\n",
      "[300]\ttrain's auc: 0.992655\ttest's auc: 0.966874\n",
      "[400]\ttrain's auc: 0.996977\ttest's auc: 0.969016\n",
      "[500]\ttrain's auc: 0.998797\ttest's auc: 0.968704\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttrain's auc: 0.99731\ttest's auc: 0.969116\n",
      "f_beta score for the turn 1 is 0.823975429504\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.95852\ttest's auc: 0.848728\n",
      "[200]\ttrain's auc: 0.981502\ttest's auc: 0.874395\n",
      "[300]\ttrain's auc: 0.993772\ttest's auc: 0.890274\n",
      "[400]\ttrain's auc: 0.998019\ttest's auc: 0.897983\n",
      "[500]\ttrain's auc: 0.999163\ttest's auc: 0.903644\n",
      "[600]\ttrain's auc: 0.999627\ttest's auc: 0.904776\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttrain's auc: 0.999497\ttest's auc: 0.905231\n",
      "f_beta score for the turn 2 is 0.319853836784\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.960136\ttest's auc: 0.930688\n",
      "[200]\ttrain's auc: 0.980579\ttest's auc: 0.944527\n",
      "[300]\ttrain's auc: 0.993529\ttest's auc: 0.951239\n",
      "[400]\ttrain's auc: 0.997809\ttest's auc: 0.95235\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttrain's auc: 0.996375\ttest's auc: 0.953221\n",
      "f_beta score for the turn 3 is 0.787187529702\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.951192\ttest's auc: 0.889307\n",
      "[200]\ttrain's auc: 0.976133\ttest's auc: 0.922904\n",
      "[300]\ttrain's auc: 0.994366\ttest's auc: 0.93637\n",
      "[400]\ttrain's auc: 0.998083\ttest's auc: 0.939523\n",
      "[500]\ttrain's auc: 0.999176\ttest's auc: 0.94206\n",
      "[600]\ttrain's auc: 0.999612\ttest's auc: 0.94252\n",
      "Early stopping, best iteration is:\n",
      "[528]\ttrain's auc: 0.999362\ttest's auc: 0.944285\n",
      "f_beta score for the turn 4 is 0.353717672414\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.939712\ttest's auc: 0.919817\n",
      "[200]\ttrain's auc: 0.976875\ttest's auc: 0.945779\n",
      "[300]\ttrain's auc: 0.992433\ttest's auc: 0.95801\n",
      "[400]\ttrain's auc: 0.997807\ttest's auc: 0.960446\n",
      "[500]\ttrain's auc: 0.999107\ttest's auc: 0.962087\n",
      "[600]\ttrain's auc: 0.999652\ttest's auc: 0.962175\n",
      "[700]\ttrain's auc: 0.999855\ttest's auc: 0.961992\n",
      "Early stopping, best iteration is:\n",
      "[661]\ttrain's auc: 0.999796\ttest's auc: 0.962535\n",
      "f_beta score for the turn 5 is 0.821669594157\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.950978\ttest's auc: 0.871611\n",
      "[200]\ttrain's auc: 0.975965\ttest's auc: 0.904438\n",
      "[300]\ttrain's auc: 0.992743\ttest's auc: 0.922761\n",
      "[400]\ttrain's auc: 0.997536\ttest's auc: 0.929614\n",
      "[500]\ttrain's auc: 0.998874\ttest's auc: 0.933156\n",
      "[600]\ttrain's auc: 0.999475\ttest's auc: 0.935006\n",
      "[700]\ttrain's auc: 0.999752\ttest's auc: 0.93593\n",
      "[800]\ttrain's auc: 0.999881\ttest's auc: 0.936424\n",
      "[900]\ttrain's auc: 0.999945\ttest's auc: 0.936779\n",
      "[1000]\ttrain's auc: 0.999977\ttest's auc: 0.938581\n",
      "Early stopping, best iteration is:\n",
      "[992]\ttrain's auc: 0.999975\ttest's auc: 0.939236\n",
      "f_beta score for the turn 6 is 0.470914742451\n",
      "The mean of the cv_scores is: 0.596219800835\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_mat[train_indice], trade_tt_mat[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = None)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_total = np.zeros(82)\n",
    "for model in models:\n",
    "    feature_importance_total+=model.feature_importance('gain')\n",
    "sorted_feature_importacne = sorted(zip(features,feature_importance_total),key = lambda x : x[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('login_distance_0', 75551.984028709499),\n",
       " ('type_c_feature_pca_15', 37090.739199137097),\n",
       " ('type_login_0', 30509.586864042794),\n",
       " ('type_c_feature_pca_0', 24345.415199079805),\n",
       " ('type_c_feature_pca_2', 22803.87469449138),\n",
       " ('login_distance_1', 17177.933923627977),\n",
       " ('type_c_feature_pca_11', 16413.767256307008),\n",
       " ('type_login_1', 15456.161692674399),\n",
       " ('type_c_feature_pca_17', 15304.810991696175),\n",
       " ('type_c_feature_pca_6', 15135.965125150215),\n",
       " ('type_c_feature_pca_4', 14030.117353038511),\n",
       " ('type_c_feature_pca_3', 13749.666635777763),\n",
       " ('timelong_login_0', 13565.087846143153),\n",
       " ('type_c_feature_pca_8', 13283.437313588576),\n",
       " ('device_comparing_login_1', 11955.85690005514),\n",
       " ('type_c_feature_pca_1', 11494.534689787082),\n",
       " ('hour_login_0', 10422.542488156687),\n",
       " ('hour_login_2', 10159.15793601726),\n",
       " ('type_c_feature_pca_12', 9985.9165180854598),\n",
       " ('device_comparing_login_2', 9466.5416318623484),\n",
       " ('hour', 9160.7807092042367),\n",
       " ('type_c_feature_pca_14', 8831.1604040759867),\n",
       " ('login_distance_2', 8088.8759181883852),\n",
       " ('type_c_feature_pca_18', 7815.7790691315586),\n",
       " ('city_login_0', 7440.714547039177),\n",
       " ('type_c_feature_pca_13', 7224.0380190420829),\n",
       " ('hour_cycle_login_0', 7140.9732081375269),\n",
       " ('type_c_feature_pca_10', 6793.8060342749386),\n",
       " ('type_c_feature_pca_9', 6506.7262718161674),\n",
       " ('type_login_2', 6481.6903923991849),\n",
       " ('timelong_login_2', 6321.5421872037168),\n",
       " ('type_c_feature_pca_19', 6189.6981753702657),\n",
       " ('type_c_feature_pca_7', 5604.6150262120618),\n",
       " ('timelong_login_1', 5111.3936175289809),\n",
       " ('city_login_1', 5084.9390365153613),\n",
       " ('city_login_2', 4699.1548936975478),\n",
       " ('result_login_1', 4517.481271864488),\n",
       " ('hour_cycle_login_2', 4479.7033941701848),\n",
       " ('type_c_feature_pca_5', 4447.4296137774081),\n",
       " ('hour_login_1', 4411.2570041876934),\n",
       " ('hour_cycle_login_1', 4109.9494139974759),\n",
       " ('hour_cycle', 3949.6827871169271),\n",
       " ('type_c_feature_pca_16', 3682.055554971801),\n",
       " ('result_login_2', 3450.6875144355436),\n",
       " ('city_comparing_login_2', 3448.8943573708557),\n",
       " ('day', 3003.7871867503691),\n",
       " ('month_login_2', 2970.9052631118752),\n",
       " ('ip_comparing_login_2', 2636.9350407177167),\n",
       " ('month_login_1', 2608.2873275844472),\n",
       " ('day_cycle', 2438.5926512332517),\n",
       " ('ip_comparing_login_1', 2295.7306406575344),\n",
       " ('day_cycle_login_1', 2187.6128820412068),\n",
       " ('day_login_1', 2159.9542464110427),\n",
       " ('result_comparing_login_1', 2144.5901167218758),\n",
       " ('day_cycle_login_2', 2107.490382791264),\n",
       " ('day_login_2', 2047.0379925030943),\n",
       " ('result_comparing_login_2', 1978.1386026419191),\n",
       " ('day_login_0', 1695.0711240975538),\n",
       " ('month', 1631.6670586824368),\n",
       " ('weekday_login_2', 1490.9908058511851),\n",
       " ('weekday_cycle_login_0', 1368.4060489402407),\n",
       " ('day_cycle_login_0', 1316.0281524443851),\n",
       " ('weekday_cycle', 1268.5808181689085),\n",
       " ('month_login_0', 925.93346238614004),\n",
       " ('weekday_cycle_login_2', 917.76163535863077),\n",
       " ('weekday', 851.70944422412435),\n",
       " ('weekday_login_0', 847.86565553307059),\n",
       " ('log_from_login_0', 839.25745326042113),\n",
       " ('log_from_login_1', 772.49172161399588),\n",
       " ('result_login_0', 758.66489309757526),\n",
       " ('weekday_cycle_login_1', 734.08827203312342),\n",
       " ('log_from_login_2', 676.63626897981965),\n",
       " ('city_comparing_login_1', 589.87290563238003),\n",
       " ('weekday_login_1', 516.15716554639403),\n",
       " ('log_from_comparing_login_1', 391.61713409227713),\n",
       " ('log_from_comparing_login_2', 303.70948085422378),\n",
       " ('type_comparing_login_1', 137.04085050901699),\n",
       " ('type_comparing_login_2', 134.89600483986806),\n",
       " ('is_scan_login_1', 11.613227237959805),\n",
       " ('is_scan_login_2', 3.2270172644873578),\n",
       " ('is_scan_login_0', 0.0),\n",
       " ('recent_login_number', 0.0)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_feature_importacne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 82 artists>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAECCAYAAAAPX/ubAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqdL/B6PkcTi8pwPoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x70b492b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "all_importance = [x[1] for x in sorted_feature_importacne]\n",
    "x = pd.Series(all_importance).sort_values(ascending = False).cumsum()\n",
    "plt.bar(range(len(x)),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config.feature_dict['type_c_pca'] = type_c_pca_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find best iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features =   (config.feature_dict['trade_detail_feature']+\n",
    "              config.feature_dict['recent_login_detail']+\n",
    "              config.feature_dict['trade_and_recent_login_comparing']+\n",
    "              config.feature_dict['login_trade_hist_stats'])\n",
    "feature_sequence_list = []\n",
    "for feature in features:\n",
    "    feature_sequence_list.append(pd.read_pickle(feature_path+feature+'.pkl').reshape(-1,1))\n",
    "trade_tt_mat = np.hstack(feature_sequence_list)\n",
    "trade_tt_mat[trade_tt_mat==-10]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating the result using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__doc__',\n",
       " '__module__',\n",
       " 'data_path',\n",
       " 'feature_dict',\n",
       " 'feature_path',\n",
       " 'model_features',\n",
       " 'result_path',\n",
       " 'single_module_validation_indice_set',\n",
       " 'trade_train_size',\n",
       " 'train_2_6_index']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = trade_tt_mat[config.train_2_6_index]\n",
    "test_X = trade_tt_mat[config.trade_train_size:]\n",
    "train_y = train_labels\n",
    "\n",
    "preds, _ = runLGBM(train_X, train_y, test_X, feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=102,watch_dict=result_dict)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
