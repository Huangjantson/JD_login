{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "import datetime\n",
    "from sklearn.metrics import fbeta_score\n",
    "import lightgbm as lgb\n",
    "from mochi import runXGB,f_beta_01,runLGBM\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data_path', 'feature_dict', 'feature_path', 'model_features', 'result_path', 'single_module_validation_indice_set', 'trade_train_size', 'train_2_6_index']\n",
      "dict_keys(['trade_and_recent_login_comparing', 'recent_login_detail', 'trade_detail_feature', 'login_trade_hist_stats', 'llc_user_habbit', 'hcc_user_habbit', 'hcc_properties', 'hcc_target_encoding', 'login_detail_new_features', 'hcc_mult_target_encoding', 'hcc_user_trade_habbit', 'hcc_trade_properties'])\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    pass\n",
    "config = pd.read_pickle('config.pkl')\n",
    "data_path = config.data_path\n",
    "feature_path = config.feature_path\n",
    "print(dir(config))\n",
    "print(config.feature_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features =   (config.feature_dict['trade_detail_feature']+\n",
    "              config.feature_dict['recent_login_detail']+\n",
    "              config.feature_dict['trade_and_recent_login_comparing']+\n",
    "              config.feature_dict['login_trade_hist_stats']+\n",
    "              config.feature_dict['llc_user_habbit']+\n",
    "             config.feature_dict['hcc_user_habbit']+\n",
    "              config.feature_dict['hcc_properties']+\n",
    "            config.feature_dict['hcc_target_encoding']+\n",
    "                    config.feature_dict['login_detail_new_features']+\n",
    "              config.feature_dict['hcc_trade_properties']+\n",
    "              config.feature_dict['hcc_mult_target_encoding']+\n",
    "              config.feature_dict['hcc_user_trade_habbit']\n",
    "             )\n",
    "feature_sequence_list = []\n",
    "for feature in features:\n",
    "    feature_sequence_list.append(pd.read_pickle(feature_path+feature+'.pkl').reshape(-1,1))\n",
    "    \n",
    "trade_tt_mat = np.hstack(feature_sequence_list)\n",
    "#trade_tt_mat[trade_tt_mat==-10]=np.nan\n",
    "\n",
    "validation_tuple_list = config.single_module_validation_indice_set\n",
    "train_labels = pd.read_pickle(data_path+'trade_train_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_features =  config.model_features['model_I_top300']\n",
    "top_features_ori_index = [features.index(x) for x in top_features]\n",
    "trade_tt_top = trade_tt_mat[:,top_features_ori_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_beta_01(preds, train_data, threshold = 0.5):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(labels, preds > threshold,0.1),True\n",
    "\n",
    "def f_beta_01_xgb(preds, train_data, threshold = 0.5):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(labels, preds > threshold,0.1)\n",
    "\n",
    "#xgb for binary\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, \n",
    "     seed_val=0, early_stop = 20,num_rounds=10000, eta = 0.1,\n",
    "     subsample = 0.75,colsample_bytree = 0.75,eval_metric = 'auc',feval = None,\n",
    "     max_depth = 6,cv_dict = None,verbose_eval=True):\n",
    "    \n",
    "    param = {}\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['eta'] = eta\n",
    "    param['max_depth'] = max_depth\n",
    "    param['silent'] = 1\n",
    "    #param['num_class'] = 3\n",
    "    param['eval_metric'] = eval_metric\n",
    "    param['min_child_weight'] = 1\n",
    "    param['subsample'] = subsample\n",
    "    param['colsample_bytree'] = colsample_bytree\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y,feature_names=feature_names)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y,feature_names=feature_names)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist,\n",
    "        early_stopping_rounds=early_stop,evals_result = cv_dict,\n",
    "        verbose_eval = verbose_eval,feval = feval)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X,feature_names=feature_names)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.882371\ttest-auc:0.855838\ttrain-fbeta_score_01:0.964524\ttest-fbeta_score_01:0.862098\n",
      "[100]\ttrain-auc:0.985347\ttest-auc:0.971877\ttrain-fbeta_score_01:0.958559\ttest-fbeta_score_01:0.882071\n",
      "[200]\ttrain-auc:0.99273\ttest-auc:0.989587\ttrain-fbeta_score_01:0.967335\ttest-fbeta_score_01:0.898731\n",
      "[300]\ttrain-auc:0.996194\ttest-auc:0.99108\ttrain-fbeta_score_01:0.967767\ttest-fbeta_score_01:0.895561\n",
      "[400]\ttrain-auc:0.9982\ttest-auc:0.990771\ttrain-fbeta_score_01:0.97209\ttest-fbeta_score_01:0.90303\n",
      "[499]\ttrain-auc:0.99913\ttest-auc:0.990448\ttrain-fbeta_score_01:0.977948\ttest-fbeta_score_01:0.893805\n",
      "f_beta score for the turn 1 is 0.915206032145\n",
      "[0]\ttrain-auc:0.928398\ttest-auc:0.807046\ttrain-fbeta_score_01:0.957272\ttest-fbeta_score_01:0.795155\n",
      "[100]\ttrain-auc:0.987671\ttest-auc:0.95393\ttrain-fbeta_score_01:0.9708\ttest-fbeta_score_01:0.858613\n",
      "[200]\ttrain-auc:0.995655\ttest-auc:0.974451\ttrain-fbeta_score_01:0.970284\ttest-fbeta_score_01:0.871612\n",
      "[300]\ttrain-auc:0.998475\ttest-auc:0.975858\ttrain-fbeta_score_01:0.971987\ttest-fbeta_score_01:0.871612\n",
      "[400]\ttrain-auc:0.99927\ttest-auc:0.976669\ttrain-fbeta_score_01:0.974731\ttest-fbeta_score_01:0.877625\n",
      "[499]\ttrain-auc:0.999677\ttest-auc:0.976191\ttrain-fbeta_score_01:0.979663\ttest-fbeta_score_01:0.867136\n",
      "f_beta score for the turn 2 is 0.906519898391\n",
      "[0]\ttrain-auc:0.916511\ttest-auc:0.909916\ttrain-fbeta_score_01:0.966168\ttest-fbeta_score_01:0.878979\n",
      "[100]\ttrain-auc:0.987788\ttest-auc:0.977443\ttrain-fbeta_score_01:0.984546\ttest-fbeta_score_01:0.909647\n",
      "[200]\ttrain-auc:0.995729\ttest-auc:0.987022\ttrain-fbeta_score_01:0.980798\ttest-fbeta_score_01:0.926659\n",
      "[300]\ttrain-auc:0.998221\ttest-auc:0.988623\ttrain-fbeta_score_01:0.978806\ttest-fbeta_score_01:0.918643\n",
      "[400]\ttrain-auc:0.99901\ttest-auc:0.989141\ttrain-fbeta_score_01:0.982991\ttest-fbeta_score_01:0.916149\n",
      "[499]\ttrain-auc:0.999424\ttest-auc:0.989116\ttrain-fbeta_score_01:0.98677\ttest-fbeta_score_01:0.912795\n",
      "f_beta score for the turn 3 is 0.945633855565\n",
      "[0]\ttrain-auc:0.880684\ttest-auc:0.824264\ttrain-fbeta_score_01:0.953061\ttest-fbeta_score_01:0.832002\n",
      "[100]\ttrain-auc:0.987419\ttest-auc:0.955908\ttrain-fbeta_score_01:0.966409\ttest-fbeta_score_01:0.895032\n",
      "[200]\ttrain-auc:0.9936\ttest-auc:0.974979\ttrain-fbeta_score_01:0.968967\ttest-fbeta_score_01:0.940232\n",
      "[300]\ttrain-auc:0.997358\ttest-auc:0.981047\ttrain-fbeta_score_01:0.972865\ttest-fbeta_score_01:0.916753\n",
      "[400]\ttrain-auc:0.9989\ttest-auc:0.982622\ttrain-fbeta_score_01:0.980061\ttest-fbeta_score_01:0.905018\n",
      "[499]\ttrain-auc:0.99953\ttest-auc:0.982427\ttrain-fbeta_score_01:0.984922\ttest-fbeta_score_01:0.906345\n",
      "f_beta score for the turn 4 is 0.992628992629\n",
      "[0]\ttrain-auc:0.88451\ttest-auc:0.84492\ttrain-fbeta_score_01:0.929622\ttest-fbeta_score_01:0.750371\n",
      "[100]\ttrain-auc:0.984205\ttest-auc:0.976445\ttrain-fbeta_score_01:0.957572\ttest-fbeta_score_01:0.845566\n",
      "[200]\ttrain-auc:0.993609\ttest-auc:0.984357\ttrain-fbeta_score_01:0.962008\ttest-fbeta_score_01:0.842729\n",
      "[300]\ttrain-auc:0.997383\ttest-auc:0.986843\ttrain-fbeta_score_01:0.969257\ttest-fbeta_score_01:0.852956\n",
      "[400]\ttrain-auc:0.998824\ttest-auc:0.987755\ttrain-fbeta_score_01:0.972343\ttest-fbeta_score_01:0.863296\n",
      "[499]\ttrain-auc:0.999456\ttest-auc:0.987629\ttrain-fbeta_score_01:0.974771\ttest-fbeta_score_01:0.863296\n",
      "f_beta score for the turn 5 is 0.892960788284\n",
      "[0]\ttrain-auc:0.883427\ttest-auc:0.847553\ttrain-fbeta_score_01:0.947765\ttest-fbeta_score_01:0.880062\n",
      "[100]\ttrain-auc:0.987188\ttest-auc:0.972033\ttrain-fbeta_score_01:0.963263\ttest-fbeta_score_01:0.926479\n",
      "[200]\ttrain-auc:0.994335\ttest-auc:0.981719\ttrain-fbeta_score_01:0.961292\ttest-fbeta_score_01:0.938345\n",
      "[300]\ttrain-auc:0.997017\ttest-auc:0.983723\ttrain-fbeta_score_01:0.963854\ttest-fbeta_score_01:0.927607\n",
      "[400]\ttrain-auc:0.998248\ttest-auc:0.985215\ttrain-fbeta_score_01:0.970024\ttest-fbeta_score_01:0.941248\n",
      "[499]\ttrain-auc:0.998964\ttest-auc:0.984687\ttrain-fbeta_score_01:0.976985\ttest-fbeta_score_01:0.915245\n",
      "f_beta score for the turn 6 is 0.962054965646\n",
      "The mean of the cv_scores is: 0.935834088777\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_top[train_indice], trade_tt_top[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \"\"\"\n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=top_features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=500,watch_dict=result_dict,feval = f_beta_01)\n",
    "    \"\"\"\n",
    "    preds, model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=top_features,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=500,cv_dict=result_dict,feval = f_beta_01_xgb ,max_depth =4)\n",
    "    \n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.8, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "#finding the best iteration\n",
    "pd_list = []\n",
    "for dic in cv_result:\n",
    "    pd_list.append(pd.DataFrame(dic['test']))\n",
    "for i in range(len(pd_list)):\n",
    "    pd_list[i].columns = pd_list[i].columns+'_'+str(i)\n",
    "validation_result = pd.concat(pd_list,axis = 1)\n",
    "validation_result['auc_avg'] = validation_result.apply(lambda x : np.mean([x.auc_0,x.auc_1,x.auc_2,x.auc_3,x.auc_4]),axis = 1)\n",
    "\n",
    "validation_result['fbeta_avg'] = validation_result.apply(lambda x : np.mean([x.fbeta_score_01_0,x.fbeta_score_01_1,\n",
    "                                                                     x.fbeta_score_01_2,x.fbeta_score_01_3,\n",
    "                                                                    x.fbeta_score_01_4]),axis=1)\n",
    "\n",
    "print(validation_result['auc_avg'].idxmax())\n",
    "print(validation_result['fbeta_avg'].idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = trade_tt_mat[config.train_2_6_index]\n",
    "test_X = trade_tt_mat[config.trade_train_size:]\n",
    "train_y = train_labels[config.train_2_6_index]\n",
    "\n",
    "preds, _ = runXGB(train_X, train_y, test_X, feature_names=features,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=365,cv_dict=None,max_depth = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_path = '../../kaggleData/JD_logging/result/'\n",
    "test_rowkey = pd.read_pickle(data_path+'trade_test_rowkey.pkl')\n",
    "pred_label = pd.Series(preds > 0.5)\n",
    "result_set = pd.DataFrame(test_rowkey)\n",
    "result_set['is_risk'] = pred_label.astype(int)\n",
    "\n",
    "print(result_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(pred_label,result_path+'adding_type_I_XGB_365.pkl')\n",
    "result_set.to_csv(result_path+'adding_type_I_XGB_365.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_top[train_indice], trade_tt_top[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \"\"\"\n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=top_features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=500,watch_dict=result_dict,feval = f_beta_01)\n",
    "    \"\"\"\n",
    "    preds, model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=top_features,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=500,cv_dict=result_dict,feval = None,max_depth =4)\n",
    "    \n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finding the best iteration\n",
    "pd_list = []\n",
    "for dic in cv_result:\n",
    "    pd_list.append(pd.DataFrame(dic['test']))\n",
    "for i in range(len(pd_list)):\n",
    "    pd_list[i].columns = pd_list[i].columns+'_'+str(i)\n",
    "validation_result = pd.concat(pd_list,axis = 1)\n",
    "validation_result['auc_avg'] = validation_result.apply(lambda x : np.mean([x.auc_0,x.auc_1,x.auc_2,x.auc_3,x.auc_4]),axis = 1)\n",
    "\"\"\"\n",
    "validation_result['fbeta_avg'] = validation_result.apply(lambda x : np.mean([x.fbeta_score_01_0,x.fbeta_score_01_1,\n",
    "                                                                     x.fbeta_score_01_2,x.fbeta_score_01_3,\n",
    "                                                                    x.fbeta_score_01_4]),axis=1)\n",
    "\"\"\"\n",
    "print(validation_result['auc_avg'].idxmax())\n",
    "#print(validation_result['fbeta_avg'].idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = trade_tt_mat[config.train_2_6_index]\n",
    "test_X = trade_tt_mat[config.trade_train_size:]\n",
    "train_y = train_labels[config.train_2_6_index]\n",
    "\n",
    "preds, _ = runXGB(train_X, train_y, test_X, feature_names=features,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=365,cv_dict=None,max_depth = 4)\n",
    "\n",
    "result_path = '../../kaggleData/JD_logging/result/'\n",
    "test_rowkey = pd.read_pickle(data_path+'trade_test_rowkey.pkl')\n",
    "pred_label = pd.Series(preds > 0.5)\n",
    "result_set = pd.DataFrame(test_rowkey)\n",
    "result_set['is_risk'] = pred_label.astype(int)\n",
    "\n",
    "print(result_set.shape)\n",
    "\n",
    "pd.to_pickle(pred_label,result_path+'adding_type_I_XGB_365_05.pkl')\n",
    "result_set.to_csv(result_path+'adding_type_I_XGB_365_05.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
