{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score,roc_auc_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pass\n",
    "config = pd.read_pickle('config.pkl')\n",
    "data_path = config.data_path\n",
    "feature_path = config.feature_path\n",
    "normalized_path = config.normalized_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_stack_path = '../../kaggleData/JD_logging/to_stack/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build feature for tree based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features =   (config.feature_dict['trade_detail_feature']+\n",
    "              config.feature_dict['recent_login_detail']+\n",
    "              config.feature_dict['trade_and_recent_login_comparing']+\n",
    "              config.feature_dict['login_trade_hist_stats']+\n",
    "              config.feature_dict['llc_user_habbit']+\n",
    "             config.feature_dict['hcc_user_habbit']+\n",
    "              config.feature_dict['hcc_properties']+\n",
    "            config.feature_dict['hcc_target_encoding']+\n",
    "                    config.feature_dict['login_detail_new_features']+\n",
    "              config.feature_dict['hcc_trade_properties']+\n",
    "              config.feature_dict['hcc_mult_target_encoding']+\n",
    "              config.feature_dict['hcc_user_trade_habbit'])\n",
    "\n",
    "feature_sequence_list = []\n",
    "for feature in features:\n",
    "    feature_sequence_list.append(pd.read_pickle(feature_path+feature+'.pkl').reshape(-1,1))\n",
    "    \n",
    "trade_tt_mat = np.hstack(feature_sequence_list)\n",
    "trade_tt_train = trade_tt_mat[config.train_2_6_index]\n",
    "trade_tt_test =  trade_tt_mat[config.test_7_index]\n",
    "\n",
    "validation_tuple_list = config.single_module_validation_indice_set\n",
    "train_labels = pd.read_pickle(data_path+'trade_train_label.pkl')[config.train_2_6_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_sequence_list = []\n",
    "for feature in config.normalized_features:\n",
    "    feature_sequence_list.append(pd.read_pickle(normalized_path+feature+'.pkl').reshape(-1,1))\n",
    "    \n",
    "trade_tt_mat_normal = np.hstack(feature_sequence_list)\n",
    "trade_tt_train_normal = trade_tt_mat[config.train_2_6_index]\n",
    "trade_tt_test_normal =  trade_tt_mat[config.test_7_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trade_tt_df = pd.DataFrame(trade_tt_mat_normal[config.train_2_6_index+config.test_7_index],columns = config.normalized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KF = KFold(5,shuffle = True, random_state = 233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#models\n",
    "from mochi import runLGBM\n",
    "from mochi import runXGB\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 7.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 7.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 7.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 7.\n",
      "  \" = {}.\".format(self.n_jobs))\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 7.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "for train_index, stack_index in KF.split(trade_tt_train_normal):\n",
    "    \n",
    "    dev_X = trade_tt_train[train_index]\n",
    "    dev_y = train_labels.iloc[train_index]\n",
    "    val_X = trade_tt_train[stack_index]\n",
    "    \n",
    "    dev_X_n = trade_tt_train_normal[train_index]\n",
    "    val_X_n = trade_tt_train_normal[stack_index]\n",
    "    \n",
    "    #LGBM\n",
    "    preds, _ = runLGBM(dev_X, dev_y, val_X, None,feature_names=None,verbose=100,eta=0.02,\n",
    "                              early_stop=None,num_rounds=390,watch_dict=None,feval = None,\n",
    "                              bagging_fraction=0.75,feature_fraction=0.25,num_leaves=64)\n",
    "    \n",
    "    trade_tt_df.loc[stack_index,'lgbm_stack'] = preds\n",
    "    \n",
    "    #XGB\n",
    "    preds, _ = runXGB(dev_X, dev_y, val_X, feature_names=None,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=365,cv_dict=None,max_depth = 6,\n",
    "                      subsample = 0.75,colsample_bytree = 0.25)\n",
    "    \n",
    "    trade_tt_df.loc[stack_index,'xgb_stack'] = preds\n",
    "    \n",
    "    #LogisticRegression\n",
    "    logR = LogisticRegression(class_weight = 'balanced',n_jobs=7)\n",
    "    logR.fit(dev_X_n,dev_y)\n",
    "    trade_tt_df.loc[stack_index,'logR_stack'] = logR.predict(val_X_n)\n",
    "    \n",
    "    #LinearRegression\n",
    "    liR = LinearRegression(n_jobs=7)\n",
    "    liR.fit(dev_X_n,dev_y)\n",
    "    trade_tt_df.loc[stack_index,'liR_stack'] = liR.predict(val_X_n)\n",
    "    \n",
    "    #RandomForestClassifier\n",
    "    classifier = RFC(200,class_weight='balanced',random_state =33,n_jobs = -1,max_depth = None,\n",
    "                        max_features = 'log2')\n",
    "    classifier.fit(dev_X,dev_y)\n",
    "    trade_tt_df.loc[stack_index,'rf_stack'] = classifier.predict(val_X)\n",
    "    \n",
    "    #KNeighborsClassifier\n",
    "    kn_3 = KNeighborsClassifier(3,n_jobs=7)\n",
    "    kn_5 = KNeighborsClassifier(5,n_jobs=7)\n",
    "    \n",
    "    kn_3.fit(dev_X_n,dev_y)\n",
    "    kn_5.fit(dev_X_n,dev_y)\n",
    "    \n",
    "    trade_tt_df.loc[stack_index,'kn3_stack'] = kn_3.predict(val_X_n)\n",
    "    trade_tt_df.loc[stack_index,'kn5_stack'] = kn_5.predict(val_X_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting the test stack features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 7.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "    dev_X = trade_tt_train\n",
    "    dev_y = train_labels\n",
    "    val_X = trade_tt_test\n",
    "    \n",
    "    dev_X_n = trade_tt_train_normal\n",
    "    val_X_n = trade_tt_test_normal\n",
    "    \n",
    "    #LGBM\n",
    "    preds, _ = runLGBM(dev_X, dev_y, val_X, None,feature_names=None,verbose=100,eta=0.02,\n",
    "                              early_stop=None,num_rounds=390,watch_dict=None,feval = None,\n",
    "                              bagging_fraction=0.75,feature_fraction=0.25,num_leaves=64)\n",
    "    \n",
    "    trade_tt_df.loc[config.test_start_stacking:,'lgbm_stack'] = preds\n",
    "    \n",
    "    #XGB\n",
    "    preds, _ = runXGB(dev_X, dev_y, val_X, feature_names=None,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=365,cv_dict=None,max_depth = 6,\n",
    "                      subsample = 0.75,colsample_bytree = 0.25)\n",
    "    \n",
    "    trade_tt_df.loc[config.test_start_stacking:,'xgb_stack'] = preds\n",
    "    \n",
    "    #LogisticRegression\n",
    "    logR = LogisticRegression(class_weight = 'balanced',n_jobs=7)\n",
    "    logR.fit(dev_X_n,dev_y)\n",
    "    trade_tt_df.loc[config.test_start_stacking:,'logR_stack'] = logR.predict(val_X_n)\n",
    "    \n",
    "    #LinearRegression\n",
    "    liR = LinearRegression(n_jobs=7)\n",
    "    liR.fit(dev_X_n,dev_y)\n",
    "    trade_tt_df.loc[config.test_start_stacking:,'liR_stack'] = liR.predict(val_X_n)\n",
    "    \n",
    "    #RandomForestClassifier\n",
    "    classifier = RFC(200,class_weight='balanced',random_state =33,n_jobs = -1,max_depth = None,\n",
    "                        max_features = 'log2')\n",
    "    classifier.fit(dev_X,dev_y)\n",
    "    trade_tt_df.loc[config.test_start_stacking:,'rf_stack'] = classifier.predict(val_X)\n",
    "    \n",
    "    #KNeighborsClassifier\n",
    "    kn_3 = KNeighborsClassifier(3,n_jobs=7)\n",
    "    kn_5 = KNeighborsClassifier(5,n_jobs=7)\n",
    "    \n",
    "    kn_3.fit(dev_X_n,dev_y)\n",
    "    kn_5.fit(dev_X_n,dev_y)\n",
    "    \n",
    "    trade_tt_df.loc[config.test_start_stacking:,'kn3_stack'] = kn_3.predict(val_X_n)\n",
    "    trade_tt_df.loc[config.test_start_stacking:,'kn5_stack'] = kn_5.predict(val_X_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the meta features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supervised_stack_set_1 = ['lgbm_stack','xgb_stack','logR_stack','liR_stack','rf_stack','kn3_stack','kn5_stack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new_trade_tt_df\n",
    "for feature in supervised_stack_set_1:\n",
    "    pd.to_pickle(trade_tt_df[feature],to_stack_path+feature+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-45b81816a2e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    pass\n",
    "config = pd.read_pickle('config.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['3sigma_detect', 'tukey_detect', 'unsupervised_detect'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.to_stack_feature_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['3sigma_detect', 'tukey_detect', 'unsupervised_detect', 'supervised_stack_set_1'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.to_stack_feature_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config.to_stack_feature_dict['supervised_stack_set_1'] = supervised_stack_set_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(config,'config.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining the meta features with unsupervised ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "features =   (config.to_stack_feature_dict['supervised_stack_set_1']+\n",
    "              config.to_stack_feature_dict['3sigma_detect']+\n",
    "              config.to_stack_feature_dict['tukey_detect']+\n",
    "              config.to_stack_feature_dict['unsupervised_detect'])\n",
    "feature_sequence_list = []\n",
    "for feature in features:\n",
    "    feature_sequence_list.append(pd.read_pickle(to_stack_path+feature+'.pkl').reshape(-1,1))\n",
    "    \n",
    "trade_tt_mat = np.hstack(feature_sequence_list)\n",
    "#trade_tt_mat[trade_tt_mat==-10]=np.nan\n",
    "\n",
    "#validation_tuple_list = config.single_module_validation_indice_set\n",
    "train_labels = pd.read_pickle(data_path+'trade_train_label.pkl')[config.train_2_6_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trade_train_mat = trade_tt_mat[:config.test_start_stacking]\n",
    "trade_test_mat = trade_tt_mat[config.test_start_stacking:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.972366\ttest-auc:0.97637\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[25]\ttrain-auc:0.992566\ttest-auc:0.992743\n",
      "\n",
      "f_beta score for the turn 1 is 0.923888231668\n",
      "[0]\ttrain-auc:0.978622\ttest-auc:0.97499\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 20 rounds.\n",
      "[100]\ttrain-auc:0.993839\ttest-auc:0.991608\n",
      "Stopping. Best iteration:\n",
      "[105]\ttrain-auc:0.993856\ttest-auc:0.991656\n",
      "\n",
      "f_beta score for the turn 2 is 0.909813100684\n",
      "[0]\ttrain-auc:0.974116\ttest-auc:0.974984\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[47]\ttrain-auc:0.991587\ttest-auc:0.994734\n",
      "\n",
      "f_beta score for the turn 3 is 0.916276111409\n",
      "[0]\ttrain-auc:0.982446\ttest-auc:0.981177\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 20 rounds.\n",
      "Stopping. Best iteration:\n",
      "[5]\ttrain-auc:0.989575\ttest-auc:0.987936\n",
      "\n",
      "f_beta score for the turn 4 is 0.89932004605\n",
      "[0]\ttrain-auc:0.985703\ttest-auc:0.979236\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 20 rounds.\n",
      "[100]\ttrain-auc:0.993643\ttest-auc:0.992855\n",
      "Stopping. Best iteration:\n",
      "[83]\ttrain-auc:0.993564\ttest-auc:0.99288\n",
      "\n",
      "f_beta score for the turn 5 is 0.910991469725\n",
      "The mean of the cv_scores is: 0.912057791907\n"
     ]
    }
   ],
   "source": [
    "val_KF = KFold(5,shuffle = True, random_state = 459)\n",
    "\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "recall_scroes = []\n",
    "precision_scores = []\n",
    "models = []\n",
    "preds_list = []\n",
    "val_list = []\n",
    "\n",
    "i=0\n",
    "         \n",
    "for train_index, stack_index in val_KF.split(trade_train_mat):\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_X = trade_train_mat[train_index]\n",
    "    dev_y = train_labels.iloc[train_index]\n",
    "    val_X = trade_train_mat[stack_index]\n",
    "    val_y = train_labels.iloc[stack_index]\n",
    "    \n",
    "    preds, model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=features,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=20,num_rounds=5000,cv_dict=result_dict,max_depth = 4,\n",
    "                      subsample = 0.75,colsample_bytree = 0.75)\n",
    "    \n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "        \n",
    "    cv_scores.append(result_f_beta)\n",
    "    recall_scroes.append(recall_score(val_y,preds > 0.5))\n",
    "    precision_scores.append(precision_score(val_y,preds > 0.5))\n",
    "    preds_list.append(preds)\n",
    "    val_list.append(val_y)\n",
    "    \n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "    \n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8897893030794165,\n",
       " 0.85521885521885521,\n",
       " 0.84161490683229812,\n",
       " 0.83614864864864868,\n",
       " 0.84868421052631582]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_scroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9242424242424242,\n",
       " 0.91039426523297495,\n",
       " 0.91708967851099832,\n",
       " 0.90000000000000002,\n",
       " 0.91166077738515905]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.92388823166769407,\n",
       " 0.90981310068447008,\n",
       " 0.91627611140867704,\n",
       " 0.89932004604979143,\n",
       " 0.91099146972451417]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test other threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_recall_scores = []\n",
    "new_precision_scores = []\n",
    "new_f_beta = []\n",
    "\n",
    "thres = 0.65\n",
    "for i in range(5):\n",
    "    new_f_beta.append(fbeta_score(val_list[i],preds_list[i] > thres, 0.1))\n",
    "    new_precision_scores.append(precision_score(val_list[i],preds_list[i] > thres))\n",
    "    new_recall_scores.append(recall_score(val_list[i],preds_list[i] > thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95141972816579201,\n",
       " 0.92976474599386294,\n",
       " 0.94926219783479171,\n",
       " 0.96523938911271434,\n",
       " 0.93187467048278982]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_f_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_beta_01_xgb(preds, train_data, threshold = 0.65):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(labels, preds > threshold,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.972366\ttest-auc:0.97637\ttrain-fbeta_score_01:0\ttest-fbeta_score_01:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain-auc:0.993571\ttest-auc:0.993394\ttrain-fbeta_score_01:0.950444\ttest-fbeta_score_01:0.940808\n",
      "[199]\ttrain-auc:0.994391\ttest-auc:0.993283\ttrain-fbeta_score_01:0.943472\ttest-fbeta_score_01:0.941787\n",
      "f_beta score for the turn 1 is 0.941787426792\n",
      "[0]\ttrain-auc:0.978622\ttest-auc:0.97499\ttrain-fbeta_score_01:0\ttest-fbeta_score_01:0\n",
      "[100]\ttrain-auc:0.993839\ttest-auc:0.991608\ttrain-fbeta_score_01:0.943649\ttest-fbeta_score_01:0.934792\n",
      "[199]\ttrain-auc:0.994347\ttest-auc:0.991253\ttrain-fbeta_score_01:0.940385\ttest-fbeta_score_01:0.927348\n",
      "f_beta score for the turn 2 is 0.927347562111\n",
      "[0]\ttrain-auc:0.974116\ttest-auc:0.974984\ttrain-fbeta_score_01:0\ttest-fbeta_score_01:0\n",
      "[100]\ttrain-auc:0.993053\ttest-auc:0.995329\ttrain-fbeta_score_01:0.941708\ttest-fbeta_score_01:0.93905\n",
      "[199]\ttrain-auc:0.993428\ttest-auc:0.995355\ttrain-fbeta_score_01:0.938708\ttest-fbeta_score_01:0.934193\n",
      "f_beta score for the turn 3 is 0.934192840973\n",
      "[0]\ttrain-auc:0.982446\ttest-auc:0.981177\ttrain-fbeta_score_01:0\ttest-fbeta_score_01:0\n",
      "[100]\ttrain-auc:0.993573\ttest-auc:0.991584\ttrain-fbeta_score_01:0.94255\ttest-fbeta_score_01:0.931546\n",
      "[199]\ttrain-auc:0.994592\ttest-auc:0.990874\ttrain-fbeta_score_01:0.940785\ttest-fbeta_score_01:0.922906\n",
      "f_beta score for the turn 4 is 0.922905628503\n",
      "[0]\ttrain-auc:0.985703\ttest-auc:0.979236\ttrain-fbeta_score_01:0\ttest-fbeta_score_01:0\n",
      "[100]\ttrain-auc:0.993643\ttest-auc:0.992855\ttrain-fbeta_score_01:0.950909\ttest-fbeta_score_01:0.931431\n",
      "[199]\ttrain-auc:0.994225\ttest-auc:0.993147\ttrain-fbeta_score_01:0.944724\ttest-fbeta_score_01:0.930867\n",
      "f_beta score for the turn 5 is 0.930866909958\n",
      "The mean of the cv_scores is: 0.931420073668\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_index, stack_index in val_KF.split(trade_train_mat):\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_X = trade_train_mat[train_index]\n",
    "    dev_y = train_labels.iloc[train_index]\n",
    "    val_X = trade_train_mat[stack_index]\n",
    "    val_y = train_labels.iloc[stack_index]\n",
    "    \n",
    "    \n",
    "    preds, model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=features,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=200,cv_dict=result_dict,max_depth = 4,\n",
    "                      subsample = 0.75,colsample_bytree = 0.75,feval = f_beta_01_xgb)\n",
    "    \"\"\"\n",
    "    preds, model = runXGB(dev_X, dev_y, val_X, val_y,feature_names=top_features,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=500,cv_dict=result_dict,feval = f_beta_01_xgb ,max_depth =4)\n",
    "     \"\"\"\n",
    "    \n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.65, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#finding the best iteration\n",
    "pd_list = []\n",
    "for dic in cv_result:\n",
    "    pd_list.append(pd.DataFrame(dic['test']))\n",
    "    \n",
    "for i in range(len(pd_list)):\n",
    "    pd_list[i].columns = pd_list[i].columns+'_'+str(i)\n",
    "validation_result = pd.concat(pd_list,axis = 1)\n",
    "validation_result['auc_avg'] = validation_result.apply(lambda x : np.mean([x.auc_0,x.auc_1,x.auc_2,x.auc_3,x.auc_4]),axis = 1)\n",
    "\n",
    "validation_result['fbeta_avg'] = validation_result.apply(lambda x : np.mean([x.fbeta_score_01_0,x.fbeta_score_01_1,\n",
    "                                                                     x.fbeta_score_01_2,x.fbeta_score_01_3,\n",
    "                                                                    x.fbeta_score_01_4]),axis=1)\n",
    "\n",
    "print(validation_result['auc_avg'].idxmax())\n",
    "print(validation_result['fbeta_avg'].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17875, 2)\n"
     ]
    }
   ],
   "source": [
    "train_X = trade_train_mat\n",
    "test_X = trade_test_mat\n",
    "train_y = train_labels\n",
    "\n",
    "preds, model = runXGB(train_X, train_y, test_X,feature_names=None,verbose_eval=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=100,cv_dict=result_dict,max_depth = 4,\n",
    "                      subsample = 0.75,colsample_bytree = 0.75,feval = f_beta_01_xgb)\n",
    "\n",
    "result_path = '../../kaggleData/JD_logging/result/'\n",
    "test_rowkey = pd.read_pickle(data_path+'trade_test_rowkey.pkl')\n",
    "pred_label = pd.Series(preds > 0.8)\n",
    "result_set = pd.DataFrame(test_rowkey)\n",
    "result_set['is_risk'] = pred_label.astype(int)\n",
    "\n",
    "print(result_set.shape)\n",
    "\n",
    "pd.to_pickle(pred_label,result_path+'stacking_sigma.pkl')\n",
    "result_set.to_csv(result_path+'stacking_sigma.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
