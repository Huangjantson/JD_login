{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "import datetime\n",
    "from sklearn.metrics import fbeta_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'data_path', 'feature_dict', 'feature_path', 'model_features', 'result_path', 'single_module_validation_indice_set', 'trade_train_size', 'train_2_6_index']\n",
      "dict_keys(['trade_and_recent_login_comparing', 'recent_login_detail', 'trade_detail_feature', 'login_trade_hist_stats', 'llc_user_habbit'])\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    pass\n",
    "config = pd.read_pickle('config.pkl')\n",
    "data_path = config.data_path\n",
    "feature_path = config.feature_path\n",
    "print(dir(config))\n",
    "print(config.feature_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model define\n",
    "\n",
    "def f_beta_01(preds, train_data):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(labels, preds > 0.5,0.1),True\n",
    "\n",
    "    \n",
    "#for binary\n",
    "def runLGBM(train_X, train_y, test_X, test_y=None, feature_names=None,\n",
    "           seed_val=0, num_rounds=10000,watch_dict = None,max_bin=50000,\n",
    "           num_leaves=16,early_stop=64,verbose=True,eta=0.1,\n",
    "           bagging_fraction = 0.75 , feature_fraction = 0.75,feval = None,metric = 'binary_logloss',\n",
    "           train_sample_weight = None):\n",
    "    \n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': eta,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': verbose,\n",
    "        'is_unbalance':False\n",
    "    }\n",
    "    \n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    #plst = list(param.items())\n",
    "    lgbtrain = lgb.Dataset(train_X, label=train_y,max_bin=max_bin,feature_name=feature_names,weight =train_sample_weight)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgbtest = lgb.Dataset(test_X, label=test_y,max_bin=max_bin,feature_name=feature_names)\n",
    "        watchlist = [lgbtrain,lgbtest]\n",
    "        watchlist_name=['train','test']\n",
    "        model = lgb.train(params, lgbtrain, num_rounds, watchlist,watchlist_name, early_stopping_rounds=early_stop,\\\n",
    "                         evals_result = watch_dict,verbose_eval=verbose,feval = feval)\n",
    "    else:\n",
    "        #lgbtest = lgb.Dataset(test_X,feature_name=feature_names)\n",
    "        model = lgb.train(params, lgbtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features =   (config.feature_dict['trade_detail_feature']+\n",
    "              config.feature_dict['recent_login_detail']+\n",
    "              config.feature_dict['trade_and_recent_login_comparing']+\n",
    "              config.feature_dict['login_trade_hist_stats']+\n",
    "              config.feature_dict['llc_user_habbit'])\n",
    "feature_sequence_list = []\n",
    "for feature in features:\n",
    "    feature_sequence_list.append(pd.read_pickle(feature_path+feature+'.pkl').reshape(-1,1))\n",
    "    \n",
    "trade_tt_mat = np.hstack(feature_sequence_list)\n",
    "#trade_tt_mat[trade_tt_mat==-10]=np.nan\n",
    "\n",
    "validation_tuple_list = config.single_module_validation_indice_set\n",
    "train_labels = pd.read_pickle(data_path+'trade_train_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's auc: 0.94953\ttrain's fbeta_score_01: 0.944129\ttest's auc: 0.931324\ttest's fbeta_score_01: 0.879095\n",
      "[200]\ttrain's auc: 0.981938\ttrain's fbeta_score_01: 0.941944\ttest's auc: 0.970328\ttest's fbeta_score_01: 0.868792\n",
      "[300]\ttrain's auc: 0.993573\ttrain's fbeta_score_01: 0.945925\ttest's auc: 0.974086\ttest's fbeta_score_01: 0.868366\n",
      "[400]\ttrain's auc: 0.997442\ttrain's fbeta_score_01: 0.95609\ttest's auc: 0.972833\ttest's fbeta_score_01: 0.869494\n",
      "[500]\ttrain's auc: 0.999131\ttrain's fbeta_score_01: 0.970335\ttest's auc: 0.972111\ttest's fbeta_score_01: 0.838767\n",
      "[600]\ttrain's auc: 0.999718\ttrain's fbeta_score_01: 0.982455\ttest's auc: 0.971147\ttest's fbeta_score_01: 0.837465\n",
      "f_beta score for the turn 1 is 0.83746509857\n",
      "[100]\ttrain's auc: 0.970026\ttrain's fbeta_score_01: 0.935398\ttest's auc: 0.852258\ttest's fbeta_score_01: 0.125466\n",
      "[200]\ttrain's auc: 0.987912\ttrain's fbeta_score_01: 0.94827\ttest's auc: 0.895263\ttest's fbeta_score_01: 0.503427\n",
      "[300]\ttrain's auc: 0.995884\ttrain's fbeta_score_01: 0.953449\ttest's auc: 0.907942\ttest's fbeta_score_01: 0.432086\n",
      "[400]\ttrain's auc: 0.998746\ttrain's fbeta_score_01: 0.961\ttest's auc: 0.915492\ttest's fbeta_score_01: 0.422866\n",
      "[500]\ttrain's auc: 0.9995\ttrain's fbeta_score_01: 0.972431\ttest's auc: 0.920535\ttest's fbeta_score_01: 0.487923\n",
      "[600]\ttrain's auc: 0.999795\ttrain's fbeta_score_01: 0.983683\ttest's auc: 0.920069\ttest's fbeta_score_01: 0.461056\n",
      "f_beta score for the turn 2 is 0.461055634807\n",
      "[100]\ttrain's auc: 0.961853\ttrain's fbeta_score_01: 0.935553\ttest's auc: 0.918301\ttest's fbeta_score_01: 0.831806\n",
      "[200]\ttrain's auc: 0.985231\ttrain's fbeta_score_01: 0.947221\ttest's auc: 0.949193\ttest's fbeta_score_01: 0.817814\n",
      "[300]\ttrain's auc: 0.995956\ttrain's fbeta_score_01: 0.956314\ttest's auc: 0.955902\ttest's fbeta_score_01: 0.818616\n",
      "[400]\ttrain's auc: 0.998853\ttrain's fbeta_score_01: 0.963035\ttest's auc: 0.959082\ttest's fbeta_score_01: 0.780264\n",
      "[500]\ttrain's auc: 0.99953\ttrain's fbeta_score_01: 0.97498\ttest's auc: 0.958024\ttest's fbeta_score_01: 0.787625\n",
      "[600]\ttrain's auc: 0.999814\ttrain's fbeta_score_01: 0.985712\ttest's auc: 0.956781\ttest's fbeta_score_01: 0.763569\n",
      "f_beta score for the turn 3 is 0.763568932316\n",
      "[100]\ttrain's auc: 0.957846\ttrain's fbeta_score_01: 0.948422\ttest's auc: 0.884399\ttest's fbeta_score_01: 0.454137\n",
      "[200]\ttrain's auc: 0.98315\ttrain's fbeta_score_01: 0.951575\ttest's auc: 0.925247\ttest's fbeta_score_01: 0.501988\n",
      "[300]\ttrain's auc: 0.996176\ttrain's fbeta_score_01: 0.956828\ttest's auc: 0.942325\ttest's fbeta_score_01: 0.618683\n",
      "[400]\ttrain's auc: 0.998678\ttrain's fbeta_score_01: 0.963948\ttest's auc: 0.94466\ttest's fbeta_score_01: 0.59587\n",
      "[500]\ttrain's auc: 0.999505\ttrain's fbeta_score_01: 0.978336\ttest's auc: 0.944683\ttest's fbeta_score_01: 0.610597\n",
      "[600]\ttrain's auc: 0.99982\ttrain's fbeta_score_01: 0.987799\ttest's auc: 0.944084\ttest's fbeta_score_01: 0.566002\n",
      "f_beta score for the turn 4 is 0.56600249066\n",
      "[100]\ttrain's auc: 0.946435\ttrain's fbeta_score_01: 0.942355\ttest's auc: 0.914212\ttest's fbeta_score_01: 0.791969\n",
      "[200]\ttrain's auc: 0.983365\ttrain's fbeta_score_01: 0.948427\ttest's auc: 0.954735\ttest's fbeta_score_01: 0.792197\n",
      "[300]\ttrain's auc: 0.995024\ttrain's fbeta_score_01: 0.956645\ttest's auc: 0.964305\ttest's fbeta_score_01: 0.777883\n",
      "[400]\ttrain's auc: 0.998656\ttrain's fbeta_score_01: 0.963891\ttest's auc: 0.962714\ttest's fbeta_score_01: 0.777137\n",
      "[500]\ttrain's auc: 0.999509\ttrain's fbeta_score_01: 0.974017\ttest's auc: 0.96045\ttest's fbeta_score_01: 0.778488\n",
      "[600]\ttrain's auc: 0.999819\ttrain's fbeta_score_01: 0.97948\ttest's auc: 0.959302\ttest's fbeta_score_01: 0.801373\n",
      "f_beta score for the turn 5 is 0.801372916109\n",
      "[100]\ttrain's auc: 0.966283\ttrain's fbeta_score_01: 0.936011\ttest's auc: 0.885422\ttest's fbeta_score_01: 0.629676\n",
      "[200]\ttrain's auc: 0.984014\ttrain's fbeta_score_01: 0.939238\ttest's auc: 0.921366\ttest's fbeta_score_01: 0.689601\n",
      "[300]\ttrain's auc: 0.995698\ttrain's fbeta_score_01: 0.954843\ttest's auc: 0.934885\ttest's fbeta_score_01: 0.652761\n",
      "[400]\ttrain's auc: 0.998363\ttrain's fbeta_score_01: 0.962832\ttest's auc: 0.939541\ttest's fbeta_score_01: 0.616537\n",
      "[500]\ttrain's auc: 0.999288\ttrain's fbeta_score_01: 0.973256\ttest's auc: 0.938642\ttest's fbeta_score_01: 0.595031\n",
      "[600]\ttrain's auc: 0.999707\ttrain's fbeta_score_01: 0.981788\ttest's auc: 0.938012\ttest's fbeta_score_01: 0.637224\n",
      "f_beta score for the turn 6 is 0.637223974763\n",
      "The mean of the cv_scores is: 0.677781507871\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "cv_result = []\n",
    "models = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    #filter the features\n",
    "    dev_X, val_X = trade_tt_mat[train_indice], trade_tt_mat[val_indice]\n",
    "    dev_y, val_y = train_labels.iloc[train_indice].values, train_labels.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=600,watch_dict=result_dict,feval = f_beta_01)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    models.append(model)\n",
    "    i+=1\n",
    "    print('f_beta score for the turn '+str(i)+' is '+str(result_f_beta))\n",
    "\n",
    "print('The mean of the cv_scores is:',np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "#finding the best iteration\n",
    "pd_list = []\n",
    "for dic in cv_result:\n",
    "    pd_list.append(pd.DataFrame(dic['test']))\n",
    "for i in range(len(pd_list)):\n",
    "    pd_list[i].columns = pd_list[i].columns+'_'+str(i)\n",
    "validation_result = pd.concat(pd_list,axis = 1)\n",
    "validation_result['auc_avg'] = validation_result.apply(lambda x : np.mean([x.auc_0,x.auc_1,x.auc_2,x.auc_3,x.auc_4]),axis = 1)\n",
    "validation_result['fbeta_avg'] = validation_result.apply(lambda x : np.mean([x.fbeta_score_01_0,x.fbeta_score_01_1,\n",
    "                                                                     x.fbeta_score_01_2,x.fbeta_score_01_3,\n",
    "                                                                     x.fbeta_score_01_4]),axis=1)\n",
    "print(validation_result['auc_avg'].idxmax())\n",
    "print(validation_result['fbeta_avg'].idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X = trade_tt_mat[config.train_2_6_index]\n",
    "test_X = trade_tt_mat[config.trade_train_size:]\n",
    "train_y = train_labels[config.train_2_6_index]\n",
    "\n",
    "preds, _ = runLGBM(train_X, train_y, test_X, feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=434,watch_dict=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17875, 2)\n"
     ]
    }
   ],
   "source": [
    "result_path = '../../kaggleData/JD_logging/result/'\n",
    "test_rowkey = pd.read_pickle(data_path+'trade_test_rowkey.pkl')\n",
    "pred_label = pd.Series(preds > 0.5)\n",
    "result_set = pd.DataFrame(test_rowkey)\n",
    "result_set['is_risk'] = pred_label.astype(int)\n",
    "\n",
    "print(result_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(pred_label,result_path+'adding_type_d_e_434.pkl')\n",
    "result_set.to_csv(result_path+'adding_type_d_e_434.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
