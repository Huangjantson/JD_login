{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt \n",
    "import datetime\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__doc__', '__module__', 'data_path', 'feature_dict', 'feature_path', 'result_path', 'single_module_validation_indice_set', 'trade_train_size']\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    pass\n",
    "config = pd.read_pickle('config.pkl')\n",
    "data_path = config.data_path\n",
    "feature_path = config.feature_path\n",
    "print dir(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trade_tt = pd.read_pickle(data_path+'trade_basic_and_recent_login.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'month', u'day', u'weekday', u'hour', u'day_cycle', u'weekday_cycle',\n",
       "       u'hour_cycle', u'timelong_login_0', u'timelong_login_1',\n",
       "       u'timelong_login_2', u'log_from_login_0', u'log_from_login_1',\n",
       "       u'log_from_login_2', u'city_login_0', u'city_login_1', u'city_login_2',\n",
       "       u'result_login_0', u'result_login_1', u'result_login_2',\n",
       "       u'type_login_0', u'type_login_1', u'type_login_2', u'is_scan_login_0',\n",
       "       u'is_scan_login_1', u'is_scan_login_2', u'month_login_0',\n",
       "       u'month_login_1', u'month_login_2', u'day_login_0', u'day_login_1',\n",
       "       u'day_login_2', u'weekday_login_0', u'weekday_login_1',\n",
       "       u'weekday_login_2', u'hour_login_0', u'hour_login_1', u'hour_login_2',\n",
       "       u'day_cycle_login_0', u'day_cycle_login_1', u'day_cycle_login_2',\n",
       "       u'weekday_cycle_login_0', u'weekday_cycle_login_1',\n",
       "       u'weekday_cycle_login_2', u'hour_cycle_login_0', u'hour_cycle_login_1',\n",
       "       u'hour_cycle_login_2', u'device_comparing_login_1',\n",
       "       u'device_comparing_login_2', u'ip_comparing_login_1',\n",
       "       u'ip_comparing_login_2', u'city_comparing_login_1',\n",
       "       u'city_comparing_login_2', u'log_from_comparing_login_1',\n",
       "       u'log_from_comparing_login_2', u'result_comparing_login_1',\n",
       "       u'result_comparing_login_2', u'type_comparing_login_1',\n",
       "       u'type_comparing_login_2', u'login_distance_0', u'login_distance_1',\n",
       "       u'login_distance_2', u'recent_login_number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_tt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del trade_tt['month_login_0']\n",
    "del trade_tt['month_login_1']\n",
    "del trade_tt['month_login_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trade_label = pd.read_pickle(data_path+'trade_train_label.pkl')\n",
    "trade_train_val = trade_tt[trade_tt['month']<7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del trade_train_val['month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f_beta_01(preds, train_data):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(labels, preds > 0.5,0.1),True\n",
    "\n",
    "    \n",
    "#for binary\n",
    "def runLGBM(train_X, train_y, test_X, test_y=None, feature_names=None,\n",
    "           seed_val=0, num_rounds=10000,watch_dict = None,max_bin=50000,\n",
    "           num_leaves=16,early_stop=64,verbose=True,eta=0.1,\n",
    "           bagging_fraction = 0.75 , feature_fraction = 0.75,feval = None,metric = 'binary_logloss',\n",
    "           train_sample_weight = None):\n",
    "    \n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_leaves': num_leaves,\n",
    "        'learning_rate': eta,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': verbose,\n",
    "        'is_unbalance':False\n",
    "    }\n",
    "    \n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    #plst = list(param.items())\n",
    "    lgbtrain = lgb.Dataset(train_X, label=train_y,max_bin=max_bin,feature_name=feature_names,weight =train_sample_weight)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgbtest = lgb.Dataset(test_X, label=test_y,max_bin=max_bin,feature_name=feature_names)\n",
    "        watchlist = [lgbtrain,lgbtest]\n",
    "        watchlist_name=['train','test']\n",
    "        model = lgb.train(params, lgbtrain, num_rounds, watchlist,watchlist_name, early_stopping_rounds=early_stop,\\\n",
    "                         evals_result = watch_dict,verbose_eval=verbose,feval = feval)\n",
    "    else:\n",
    "        #lgbtest = lgb.Dataset(test_X,feature_name=feature_names)\n",
    "        model = lgb.train(params, lgbtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X)\n",
    "    return pred_test_y, model\n",
    "\n",
    "config.f_beta = f_beta_01\n",
    "config.LGBM = runLGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_tuple_list = config.single_module_validation_indice_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding id By bear's request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trade_train = pd.read_csv(data_path+'t_trade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_trade_val = pd.DataFrame(trade_train_val)\n",
    "temp_trade_val['id'] = trade_train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.924073\ttest's auc: 0.941208\n",
      "[200]\ttrain's auc: 0.971376\ttest's auc: 0.945075\n",
      "[300]\ttrain's auc: 0.985458\ttest's auc: 0.948961\n",
      "[400]\ttrain's auc: 0.991473\ttest's auc: 0.950296\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttrain's auc: 0.991265\ttest's auc: 0.950425\n",
      "f_beta score for the turn 1 is 0.839009802293\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.936519\ttest's auc: 0.810354\n",
      "[200]\ttrain's auc: 0.967882\ttest's auc: 0.836138\n",
      "[300]\ttrain's auc: 0.985846\ttest's auc: 0.848953\n",
      "[400]\ttrain's auc: 0.994338\ttest's auc: 0.850113\n",
      "[500]\ttrain's auc: 0.997506\ttest's auc: 0.848031\n",
      "Early stopping, best iteration is:\n",
      "[423]\ttrain's auc: 0.995581\ttest's auc: 0.852409\n",
      "f_beta score for the turn 2 is 0.403327787022\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.940192\ttest's auc: 0.905573\n",
      "[200]\ttrain's auc: 0.974281\ttest's auc: 0.916882\n",
      "[300]\ttrain's auc: 0.984998\ttest's auc: 0.920911\n",
      "[400]\ttrain's auc: 0.993037\ttest's auc: 0.922486\n",
      "[500]\ttrain's auc: 0.996789\ttest's auc: 0.92272\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttrain's auc: 0.994368\ttest's auc: 0.923405\n",
      "f_beta score for the turn 3 is 0.732547597461\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.943104\ttest's auc: 0.859493\n",
      "[200]\ttrain's auc: 0.967604\ttest's auc: 0.870877\n",
      "[300]\ttrain's auc: 0.986859\ttest's auc: 0.879195\n",
      "[400]\ttrain's auc: 0.994846\ttest's auc: 0.882464\n",
      "[500]\ttrain's auc: 0.997755\ttest's auc: 0.883097\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttrain's auc: 0.995983\ttest's auc: 0.884066\n",
      "f_beta score for the turn 4 is 0.260693215339\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.925747\ttest's auc: 0.926045\n",
      "[200]\ttrain's auc: 0.967055\ttest's auc: 0.930224\n",
      "[300]\ttrain's auc: 0.984209\ttest's auc: 0.935421\n",
      "[400]\ttrain's auc: 0.993225\ttest's auc: 0.937617\n",
      "[500]\ttrain's auc: 0.997088\ttest's auc: 0.937323\n",
      "Early stopping, best iteration is:\n",
      "[415]\ttrain's auc: 0.994056\ttest's auc: 0.939249\n",
      "f_beta score for the turn 5 is 0.77389041492\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.935778\ttest's auc: 0.816589\n",
      "[200]\ttrain's auc: 0.966774\ttest's auc: 0.844231\n",
      "[300]\ttrain's auc: 0.984345\ttest's auc: 0.857634\n",
      "[400]\ttrain's auc: 0.992248\ttest's auc: 0.861399\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttrain's auc: 0.990924\ttest's auc: 0.863398\n",
      "f_beta score for the turn 6 is 0.378119800333\n",
      "The mean of the cv_scores is:\n",
      "0.564598102895\n"
     ]
    }
   ],
   "source": [
    "#using all features\n",
    "features = list(trade_train_val.columns)\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = temp_trade_val.iloc[train_indice,:] , temp_trade_val.iloc[val_indice,:] \n",
    "    #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = trade_label.iloc[train_indice].values, trade_label.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = None)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation with f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.928248\ttrain's fbeta_score_01: 0.391588\ttest's auc: 0.937303\ttest's fbeta_score_01: 0.128926\n",
      "[200]\ttrain's auc: 0.971438\ttrain's fbeta_score_01: 0.482688\ttest's auc: 0.944449\ttest's fbeta_score_01: 0.188673\n",
      "[300]\ttrain's auc: 0.984632\ttrain's fbeta_score_01: 0.598789\ttest's auc: 0.947406\ttest's fbeta_score_01: 0.216195\n",
      "[400]\ttrain's auc: 0.991182\ttrain's fbeta_score_01: 0.660241\ttest's auc: 0.950272\ttest's fbeta_score_01: 0.239151\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttrain's auc: 0.989696\ttrain's fbeta_score_01: 0.639303\ttest's auc: 0.948855\ttest's fbeta_score_01: 0.252902\n",
      "f_beta score for the turn 1 is 0.826759934514\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.937482\ttrain's fbeta_score_01: 0.40978\ttest's auc: 0.813827\ttest's fbeta_score_01: 0.0576539\n",
      "[200]\ttrain's auc: 0.967438\ttrain's fbeta_score_01: 0.476834\ttest's auc: 0.837802\ttest's fbeta_score_01: 0.0960076\n",
      "[300]\ttrain's auc: 0.985526\ttrain's fbeta_score_01: 0.567877\ttest's auc: 0.8533\ttest's fbeta_score_01: 0.105548\n",
      "Early stopping, best iteration is:\n",
      "[228]\ttrain's auc: 0.974725\ttrain's fbeta_score_01: 0.494266\ttest's auc: 0.846359\ttest's fbeta_score_01: 0.105558\n",
      "f_beta score for the turn 2 is 0.426487523992\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.940939\ttrain's fbeta_score_01: 0.388723\ttest's auc: 0.905805\ttest's fbeta_score_01: 0.104947\n",
      "[200]\ttrain's auc: 0.973318\ttrain's fbeta_score_01: 0.479036\ttest's auc: 0.917203\ttest's fbeta_score_01: 0.159586\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttrain's auc: 0.965524\ttrain's fbeta_score_01: 0.470585\ttest's auc: 0.919624\ttest's fbeta_score_01: 0.150481\n",
      "f_beta score for the turn 3 is 0.650849443468\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.94124\ttrain's fbeta_score_01: 0.439348\ttest's auc: 0.850911\ttest's fbeta_score_01: 0.0270294\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttrain's auc: 0.909743\ttrain's fbeta_score_01: 0.31042\ttest's auc: 0.80686\ttest's fbeta_score_01: 0.0629508\n",
      "f_beta score for the turn 4 is 0.220112079701\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.928556\ttrain's fbeta_score_01: 0.375356\ttest's auc: 0.922503\ttest's fbeta_score_01: 0.139406\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's auc: 0.795563\ttrain's fbeta_score_01: 0.339664\ttest's auc: 0.83686\ttest's fbeta_score_01: 0.199367\n",
      "f_beta score for the turn 5 is 0.504003713589\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.937756\ttrain's fbeta_score_01: 0.421406\ttest's auc: 0.822145\ttest's fbeta_score_01: 0.0291122\n",
      "[200]\ttrain's auc: 0.967651\ttrain's fbeta_score_01: 0.504967\ttest's auc: 0.846347\ttest's fbeta_score_01: 0.0775655\n",
      "[300]\ttrain's auc: 0.984399\ttrain's fbeta_score_01: 0.581791\ttest's auc: 0.859974\ttest's fbeta_score_01: 0.0872193\n",
      "Early stopping, best iteration is:\n",
      "[245]\ttrain's auc: 0.976755\ttrain's fbeta_score_01: 0.532799\ttest's auc: 0.856282\ttest's fbeta_score_01: 0.0872277\n",
      "f_beta score for the turn 6 is 0.412431941924\n",
      "The mean of the cv_scores is:\n",
      "0.506774106198\n"
     ]
    }
   ],
   "source": [
    "#using all features\n",
    "features = list(trade_train_val.columns)\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = trade_train_val.iloc[train_indice,:] , trade_train_val.iloc[val_indice,:] \n",
    "    #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = trade_label.iloc[train_indice].values, trade_label.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = f_beta_01)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Validation without f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.928248\ttest's auc: 0.937303\n",
      "[200]\ttrain's auc: 0.971438\ttest's auc: 0.944449\n",
      "[300]\ttrain's auc: 0.984632\ttest's auc: 0.947406\n",
      "[400]\ttrain's auc: 0.991182\ttest's auc: 0.950272\n",
      "Early stopping, best iteration is:\n",
      "[397]\ttrain's auc: 0.991091\ttest's auc: 0.950372\n",
      "f_beta score for the turn 1 is 0.833930518772\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.937482\ttest's auc: 0.813827\n",
      "[200]\ttrain's auc: 0.967438\ttest's auc: 0.837802\n",
      "[300]\ttrain's auc: 0.985526\ttest's auc: 0.8533\n",
      "[400]\ttrain's auc: 0.993768\ttest's auc: 0.85558\n",
      "[500]\ttrain's auc: 0.996887\ttest's auc: 0.854338\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttrain's auc: 0.994503\ttest's auc: 0.856286\n",
      "f_beta score for the turn 2 is 0.432085561497\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.940939\ttest's auc: 0.905805\n",
      "[200]\ttrain's auc: 0.973318\ttest's auc: 0.917203\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttrain's auc: 0.965524\ttest's auc: 0.919624\n",
      "f_beta score for the turn 3 is 0.650849443468\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.94124\ttest's auc: 0.850911\n",
      "[200]\ttrain's auc: 0.968247\ttest's auc: 0.877281\n",
      "[300]\ttrain's auc: 0.985897\ttest's auc: 0.884133\n",
      "[400]\ttrain's auc: 0.993263\ttest's auc: 0.889462\n",
      "Early stopping, best iteration is:\n",
      "[388]\ttrain's auc: 0.99263\ttest's auc: 0.89048\n",
      "f_beta score for the turn 4 is 0.28733997155\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.928556\ttest's auc: 0.922503\n",
      "[200]\ttrain's auc: 0.965488\ttest's auc: 0.926163\n",
      "[300]\ttrain's auc: 0.983325\ttest's auc: 0.932948\n",
      "[400]\ttrain's auc: 0.990852\ttest's auc: 0.93646\n",
      "[500]\ttrain's auc: 0.995198\ttest's auc: 0.936403\n",
      "Early stopping, best iteration is:\n",
      "[450]\ttrain's auc: 0.993197\ttest's auc: 0.937504\n",
      "f_beta score for the turn 5 is 0.814404810715\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.937756\ttest's auc: 0.822145\n",
      "[200]\ttrain's auc: 0.967651\ttest's auc: 0.846347\n",
      "[300]\ttrain's auc: 0.984399\ttest's auc: 0.859974\n",
      "[400]\ttrain's auc: 0.99201\ttest's auc: 0.862971\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttrain's auc: 0.99135\ttest's auc: 0.864472\n",
      "f_beta score for the turn 6 is 0.39453125\n",
      "The mean of the cv_scores is:\n",
      "0.568856926001\n"
     ]
    }
   ],
   "source": [
    "#using all features\n",
    "features = list(trade_train_val.columns)\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = trade_train_val.iloc[train_indice,:] , trade_train_val.iloc[val_indice,:] \n",
    "    #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = trade_label.iloc[train_indice].values, trade_label.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = None)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking up features by their gain importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = trade_train_val.as_matrix()\n",
    "test_X =  trade_tt[trade_tt['month']>6].as_matrix() \n",
    "train_y = trade_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using binary logloss and auc and picking up the feature importance\n",
    "preds, model = runLGBM(train_X, train_y, test_X, feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=350,watch_dict=result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_features = sorted(zip(features,model.feature_importance('gain')),key = lambda x : x[1],reverse = True)\n",
    "pickup_feature_basic_comparing_detail =[x[0] for x in sorted_features[:len(sorted_features)/4*3]]\n",
    "all_importance = [x[1] for x in sorted_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('login_distance_0', 53360.023090910581),\n",
       " ('login_distance_1', 34923.374836857802),\n",
       " ('type_login_0', 19677.441689525629),\n",
       " ('login_distance_2', 17189.206321323349),\n",
       " ('hour_login_0', 16486.792560164427),\n",
       " ('device_comparing_login_1', 14709.854671406531),\n",
       " ('type_login_1', 12692.426649733794),\n",
       " ('timelong_login_0', 12510.633685847781),\n",
       " ('result_login_1', 9039.6209951457004),\n",
       " ('device_comparing_login_2', 8477.8499201496525),\n",
       " ('city_login_0', 7984.2215024065254),\n",
       " ('hour_login_2', 7582.7215749194738),\n",
       " ('hour_cycle_login_0', 6609.1007134229294),\n",
       " ('day_cycle_login_1', 6593.9375721544639),\n",
       " ('city_login_1', 6518.9973137301267),\n",
       " ('hour', 5885.8809720959871),\n",
       " ('result_login_2', 5728.2250223302099),\n",
       " ('type_login_2', 5418.1832968974622),\n",
       " ('timelong_login_2', 5159.1263669833534),\n",
       " ('hour_cycle_login_2', 5124.5753538053368),\n",
       " ('city_login_2', 4496.3821204959995),\n",
       " ('hour_cycle_login_1', 4448.4794468788405),\n",
       " ('hour_login_1', 3948.1032886730977),\n",
       " ('city_comparing_login_2', 3916.7407036673249),\n",
       " ('day_cycle_login_2', 3816.3091075744187),\n",
       " ('hour_cycle', 3613.3798820004909),\n",
       " ('log_from_login_1', 3543.6069197726324),\n",
       " ('day_login_2', 3430.749660303311),\n",
       " ('ip_comparing_login_1', 3172.8450565727576),\n",
       " ('log_from_login_0', 3049.3297568704102),\n",
       " ('log_from_login_2', 3007.2790025995646),\n",
       " ('day', 2846.5161356827507),\n",
       " ('timelong_login_1', 2588.3648840081341),\n",
       " ('day_cycle_login_0', 2438.1562946670119),\n",
       " ('result_comparing_login_2', 2333.5392213299556),\n",
       " ('result_comparing_login_1', 2299.2988246736822),\n",
       " ('day_login_0', 2224.32582678777),\n",
       " ('day_cycle', 1958.1308780901584),\n",
       " ('weekday_login_2', 1600.5661320687509),\n",
       " ('ip_comparing_login_2', 1521.7065219564399),\n",
       " ('day_login_1', 1409.1419517265658),\n",
       " ('weekday_cycle', 990.83631163164046),\n",
       " ('weekday_cycle_login_0', 649.68086823905526),\n",
       " ('city_comparing_login_1', 645.68095668615922),\n",
       " ('weekday_cycle_login_1', 626.06335661654089),\n",
       " ('type_comparing_login_2', 494.95385496367493),\n",
       " ('weekday', 494.43713474699047),\n",
       " ('weekday_login_1', 482.63766780505676),\n",
       " ('weekday_cycle_login_2', 346.06616073524361),\n",
       " ('result_login_0', 226.85151764689948),\n",
       " ('weekday_login_0', 203.50710898751441),\n",
       " ('log_from_comparing_login_1', 160.84309716371186),\n",
       " ('type_comparing_login_1', 153.26980861286029),\n",
       " ('recent_login_number', 113.77794474741121),\n",
       " ('log_from_comparing_login_2', 81.410614871714486),\n",
       " ('is_scan_login_0', 0.0),\n",
       " ('is_scan_login_1', 0.0),\n",
       " ('is_scan_login_2', 0.0)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 58 artists>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAECCAYAAAAPX/ubAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkkoZFpKkUoaFJKnU/we7t0Qh5txpiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a553cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#显示从大到小的cumsum，看是否存在明显的8020\n",
    "%matplotlib inline\n",
    "x = pd.Series(all_importance).sort_values(ascending = False).cumsum()\n",
    "plt.bar(range(len(x)),x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.926605\ttrain's fbeta_score_01: 0.383189\ttest's auc: 0.935526\ttest's fbeta_score_01: 0.133531\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's auc: 0.858088\ttrain's fbeta_score_01: 0.311107\ttest's auc: 0.881576\ttest's fbeta_score_01: 0.33948\n",
      "f_beta score for the turn 1 is 0.632371605043\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.934817\ttrain's fbeta_score_01: 0.40441\ttest's auc: 0.801351\ttest's fbeta_score_01: 0.0576539\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttrain's auc: 0.880223\ttrain's fbeta_score_01: 0.310267\ttest's auc: 0.750823\ttest's fbeta_score_01: 0.0768134\n",
      "f_beta score for the turn 2 is 0.402992518703\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.941281\ttrain's fbeta_score_01: 0.394359\ttest's auc: 0.904298\ttest's fbeta_score_01: 0.13685\n",
      "[200]\ttrain's auc: 0.973141\ttrain's fbeta_score_01: 0.48185\ttest's auc: 0.916115\ttest's fbeta_score_01: 0.186894\n",
      "[300]\ttrain's auc: 0.98315\ttrain's fbeta_score_01: 0.587547\ttest's auc: 0.921167\ttest's fbeta_score_01: 0.209619\n",
      "[400]\ttrain's auc: 0.990977\ttrain's fbeta_score_01: 0.659262\ttest's auc: 0.922782\ttest's fbeta_score_01: 0.236886\n",
      "[500]\ttrain's auc: 0.995407\ttrain's fbeta_score_01: 0.726741\ttest's auc: 0.923853\ttest's fbeta_score_01: 0.268714\n",
      "[600]\ttrain's auc: 0.997931\ttrain's fbeta_score_01: 0.764638\ttest's auc: 0.923361\ttest's fbeta_score_01: 0.264231\n",
      "Early stopping, best iteration is:\n",
      "[515]\ttrain's auc: 0.995793\ttrain's fbeta_score_01: 0.732355\ttest's auc: 0.924774\ttest's fbeta_score_01: 0.26875\n",
      "f_beta score for the turn 3 is 0.792314851748\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.942439\ttrain's fbeta_score_01: 0.445928\ttest's auc: 0.859442\ttest's fbeta_score_01: 0.0270246\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttrain's auc: 0.872712\ttrain's fbeta_score_01: 0.399762\ttest's auc: 0.761015\ttest's fbeta_score_01: 0.0449969\n",
      "f_beta score for the turn 4 is 0.209369817579\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.926383\ttrain's fbeta_score_01: 0.383007\ttest's auc: 0.920691\ttest's fbeta_score_01: 0.167226\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttrain's auc: 0.796768\ttrain's fbeta_score_01: 0.313708\ttest's auc: 0.840394\ttest's fbeta_score_01: 0.204012\n",
      "f_beta score for the turn 5 is 0.521779969473\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.93209\ttrain's fbeta_score_01: 0.421389\ttest's auc: 0.815477\ttest's fbeta_score_01: 0.0388088\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttrain's auc: 0.918271\ttrain's fbeta_score_01: 0.378877\ttest's auc: 0.826198\ttest's fbeta_score_01: 0.00970687\n",
      "f_beta score for the turn 6 is 0.167218543046\n",
      "The mean of the cv_scores is:\n",
      "0.454341217599\n"
     ]
    }
   ],
   "source": [
    "#using all features\n",
    "features = list(trade_train_val.columns)\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = trade_train_val.iloc[train_indice,:] , trade_train_val.iloc[val_indice,:] \n",
    "    #filter the features\n",
    "    dev_X, val_X = dev_set[pickup_feature_basic_comparing_detail].as_matrix(), val_set[pickup_feature_basic_comparing_detail].as_matrix()\n",
    "    dev_y, val_y = trade_label.iloc[train_indice].values, trade_label.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=pickup_feature_basic_comparing_detail,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = f_beta_01)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying other threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.928248\ttrain's fbeta_score_01: 0.610514\ttest's auc: 0.937303\ttest's fbeta_score_01: 0.375942\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttrain's auc: 0.911035\ttrain's fbeta_score_01: 0.829507\ttest's auc: 0.932783\ttest's fbeta_score_01: 0.852039\n",
      "f_beta score for the turn 1 is 0.681619690353\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.937482\ttrain's fbeta_score_01: 0.600583\ttest's auc: 0.813827\ttest's fbeta_score_01: 0.171996\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttrain's auc: 0.928659\ttrain's fbeta_score_01: 0.845753\ttest's auc: 0.809007\ttest's fbeta_score_01: 0.631782\n",
      "f_beta score for the turn 2 is 0.558011049724\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.940939\ttrain's fbeta_score_01: 0.614923\ttest's auc: 0.905805\ttest's fbeta_score_01: 0.331758\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's auc: 0.8362\ttrain's fbeta_score_01: 0.783537\ttest's auc: 0.843649\ttest's fbeta_score_01: 0.782205\n",
      "f_beta score for the turn 3 is 0.415278078338\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.94124\ttrain's fbeta_score_01: 0.61964\ttest's auc: 0.850911\ttest's fbeta_score_01: 0.0807713\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttrain's auc: 0.927078\ttrain's fbeta_score_01: 0.85825\ttest's auc: 0.821087\ttest's fbeta_score_01: 0.601708\n",
      "f_beta score for the turn 4 is 0.165032679739\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.928556\ttrain's fbeta_score_01: 0.544553\ttest's auc: 0.922503\ttest's fbeta_score_01: 0.338071\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttrain's auc: 0.904442\ttrain's fbeta_score_01: 0.784238\ttest's auc: 0.910277\ttest's fbeta_score_01: 0.788447\n",
      "f_beta score for the turn 5 is 0.751115518096\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.937756\ttrain's fbeta_score_01: 0.592999\ttest's auc: 0.822145\ttest's fbeta_score_01: 0.115936\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's auc: 0.857423\ttrain's fbeta_score_01: 0.801638\ttest's auc: 0.731692\ttest's fbeta_score_01: 0.531203\n",
      "f_beta score for the turn 6 is 0.0288242009132\n",
      "The mean of the cv_scores is:\n",
      "0.433313536194\n"
     ]
    }
   ],
   "source": [
    "def f_beta_01(preds, train_data):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(preds > 0.3,labels,0.1),True\n",
    "\n",
    "#using all features\n",
    "features = list(trade_train_val.columns)\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = trade_train_val.iloc[train_indice,:] , trade_train_val.iloc[val_indice,:] \n",
    "    #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = trade_label.iloc[train_indice].values, trade_label.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = f_beta_01)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding the sample weighting for label ==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.96477\ttrain's fbeta_score_01: 0.457801\ttest's auc: 0.944985\ttest's fbeta_score_01: 0.476088\n",
      "[200]\ttrain's auc: 0.981079\ttrain's fbeta_score_01: 0.536524\ttest's auc: 0.947545\ttest's fbeta_score_01: 0.503081\n",
      "[300]\ttrain's auc: 0.988898\ttrain's fbeta_score_01: 0.592707\ttest's auc: 0.949061\ttest's fbeta_score_01: 0.539238\n",
      "[400]\ttrain's auc: 0.993245\ttrain's fbeta_score_01: 0.641571\ttest's auc: 0.949594\ttest's fbeta_score_01: 0.547165\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttrain's auc: 0.992896\ttrain's fbeta_score_01: 0.639971\ttest's auc: 0.949888\ttest's fbeta_score_01: 0.549175\n",
      "f_beta score for the turn 1 is 0.549175208494\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.963657\ttrain's fbeta_score_01: 0.450018\ttest's auc: 0.843971\ttest's fbeta_score_01: 0.0912513\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttrain's auc: 0.952304\ttrain's fbeta_score_01: 0.444658\ttest's auc: 0.839991\ttest's fbeta_score_01: 0.0920833\n",
      "f_beta score for the turn 2 is 0.0920832700198\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.965836\ttrain's fbeta_score_01: 0.449397\ttest's auc: 0.920616\ttest's fbeta_score_01: 0.382565\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's auc: 0.95205\ttrain's fbeta_score_01: 0.415237\ttest's auc: 0.915294\ttest's fbeta_score_01: 0.394868\n",
      "f_beta score for the turn 3 is 0.39486798271\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.963647\ttrain's fbeta_score_01: 0.512422\ttest's auc: 0.879293\ttest's fbeta_score_01: 0.0957975\n",
      "[200]\ttrain's auc: 0.982011\ttrain's fbeta_score_01: 0.561587\ttest's auc: 0.888052\ttest's fbeta_score_01: 0.106059\n",
      "[300]\ttrain's auc: 0.990789\ttrain's fbeta_score_01: 0.608542\ttest's auc: 0.886195\ttest's fbeta_score_01: 0.114903\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttrain's auc: 0.982011\ttrain's fbeta_score_01: 0.561587\ttest's auc: 0.888052\ttest's fbeta_score_01: 0.106059\n",
      "f_beta score for the turn 4 is 0.106059427505\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.962334\ttrain's fbeta_score_01: 0.449079\ttest's auc: 0.926022\ttest's fbeta_score_01: 0.41216\n",
      "[200]\ttrain's auc: 0.97977\ttrain's fbeta_score_01: 0.513441\ttest's auc: 0.933652\ttest's fbeta_score_01: 0.439173\n",
      "[300]\ttrain's auc: 0.988714\ttrain's fbeta_score_01: 0.560925\ttest's auc: 0.933995\ttest's fbeta_score_01: 0.451759\n",
      "[400]\ttrain's auc: 0.993297\ttrain's fbeta_score_01: 0.616122\ttest's auc: 0.936634\ttest's fbeta_score_01: 0.482082\n",
      "[500]\ttrain's auc: 0.995773\ttrain's fbeta_score_01: 0.660963\ttest's auc: 0.935012\ttest's fbeta_score_01: 0.510877\n",
      "Early stopping, best iteration is:\n",
      "[401]\ttrain's auc: 0.993328\ttrain's fbeta_score_01: 0.616529\ttest's auc: 0.936721\ttest's fbeta_score_01: 0.483887\n",
      "f_beta score for the turn 5 is 0.483886663922\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttrain's auc: 0.963816\ttrain's fbeta_score_01: 0.454857\ttest's auc: 0.841844\ttest's fbeta_score_01: 0.0876933\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttrain's auc: 0.939887\ttrain's fbeta_score_01: 0.439818\ttest's auc: 0.859328\ttest's fbeta_score_01: 0.0790869\n",
      "f_beta score for the turn 6 is 0.0790868570052\n",
      "The mean of the cv_scores is:\n",
      "0.284193234943\n"
     ]
    }
   ],
   "source": [
    "#using all features\n",
    "features = list(trade_train_val.columns)\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = trade_train_val.iloc[train_indice,:] , trade_train_val.iloc[val_indice,:] \n",
    "    #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = trade_label.iloc[train_indice].values, trade_label.iloc[val_indice].values\n",
    "    \n",
    "    dev_weight = np.array([10 if x==1 else 1 for x in dev_y])\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=100,num_rounds=3500,watch_dict=result_dict,feval = f_beta_01,train_sample_weight = dev_weight)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the best result without using f_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's auc: 0.928248\ttrain's fbeta_score_01: 0.905333\ttest's auc: 0.937303\ttest's fbeta_score_01: 0.760419\n",
      "[200]\ttrain's auc: 0.971438\ttrain's fbeta_score_01: 0.916142\ttest's auc: 0.944449\ttest's fbeta_score_01: 0.825065\n",
      "[300]\ttrain's auc: 0.984632\ttrain's fbeta_score_01: 0.931017\ttest's auc: 0.947406\ttest's fbeta_score_01: 0.801994\n",
      "[400]\ttrain's auc: 0.991182\ttrain's fbeta_score_01: 0.939739\ttest's auc: 0.950272\ttest's fbeta_score_01: 0.831144\n",
      "f_beta score for the turn 1 is 0.831144168381\n",
      "[100]\ttrain's auc: 0.937482\ttrain's fbeta_score_01: 0.915281\ttest's auc: 0.813827\ttest's fbeta_score_01: 0.502905\n",
      "[200]\ttrain's auc: 0.967438\ttrain's fbeta_score_01: 0.91804\ttest's auc: 0.837802\ttest's fbeta_score_01: 0.47981\n",
      "[300]\ttrain's auc: 0.985526\ttrain's fbeta_score_01: 0.921636\ttest's auc: 0.8533\ttest's fbeta_score_01: 0.410721\n",
      "[400]\ttrain's auc: 0.993768\ttrain's fbeta_score_01: 0.93911\ttest's auc: 0.85558\ttest's fbeta_score_01: 0.410721\n",
      "f_beta score for the turn 2 is 0.410720887246\n",
      "[100]\ttrain's auc: 0.940939\ttrain's fbeta_score_01: 0.925273\ttest's auc: 0.905805\ttest's fbeta_score_01: 0.624295\n",
      "[200]\ttrain's auc: 0.973318\ttrain's fbeta_score_01: 0.919939\ttest's auc: 0.917203\ttest's fbeta_score_01: 0.664349\n",
      "[300]\ttrain's auc: 0.984555\ttrain's fbeta_score_01: 0.939923\ttest's auc: 0.920636\ttest's fbeta_score_01: 0.704534\n",
      "[400]\ttrain's auc: 0.991594\ttrain's fbeta_score_01: 0.949038\ttest's auc: 0.922326\ttest's fbeta_score_01: 0.736349\n",
      "f_beta score for the turn 3 is 0.736348757625\n",
      "[100]\ttrain's auc: 0.94124\ttrain's fbeta_score_01: 0.935237\ttest's auc: 0.850911\ttest's fbeta_score_01: 0.272482\n",
      "[200]\ttrain's auc: 0.968247\ttrain's fbeta_score_01: 0.943491\ttest's auc: 0.877281\ttest's fbeta_score_01: 0.23911\n",
      "[300]\ttrain's auc: 0.985897\ttrain's fbeta_score_01: 0.945563\ttest's auc: 0.884133\ttest's fbeta_score_01: 0.20937\n",
      "[400]\ttrain's auc: 0.993263\ttrain's fbeta_score_01: 0.953936\ttest's auc: 0.889462\ttest's fbeta_score_01: 0.28734\n",
      "f_beta score for the turn 4 is 0.28733997155\n",
      "[100]\ttrain's auc: 0.928556\ttrain's fbeta_score_01: 0.942265\ttest's auc: 0.922503\ttest's fbeta_score_01: 0.815174\n",
      "[200]\ttrain's auc: 0.965488\ttrain's fbeta_score_01: 0.941053\ttest's auc: 0.926163\ttest's fbeta_score_01: 0.718934\n",
      "[300]\ttrain's auc: 0.983325\ttrain's fbeta_score_01: 0.952223\ttest's auc: 0.932948\ttest's fbeta_score_01: 0.767453\n",
      "[400]\ttrain's auc: 0.990852\ttrain's fbeta_score_01: 0.952228\ttest's auc: 0.93646\ttest's fbeta_score_01: 0.791649\n",
      "f_beta score for the turn 5 is 0.791648852786\n",
      "[100]\ttrain's auc: 0.937756\ttrain's fbeta_score_01: 0.926337\ttest's auc: 0.822145\ttest's fbeta_score_01: 0.335177\n",
      "[200]\ttrain's auc: 0.967651\ttrain's fbeta_score_01: 0.927886\ttest's auc: 0.846347\ttest's fbeta_score_01: 0.447894\n",
      "[300]\ttrain's auc: 0.984399\ttrain's fbeta_score_01: 0.936018\ttest's auc: 0.859974\ttest's fbeta_score_01: 0.394531\n",
      "[400]\ttrain's auc: 0.99201\ttrain's fbeta_score_01: 0.949501\ttest's auc: 0.862971\ttest's fbeta_score_01: 0.394531\n",
      "f_beta score for the turn 6 is 0.39453125\n",
      "The mean of the cv_scores is:\n",
      "0.575288981265\n"
     ]
    }
   ],
   "source": [
    "#finding the best iteration\n",
    "\n",
    "def f_beta_01(preds, train_data):\n",
    "    labels  = train_data.get_label()\n",
    "    return 'fbeta_score_01',fbeta_score(labels, preds > 0.5,0.1),True\n",
    "\n",
    "#using all features\n",
    "features = list(trade_train_val.columns)\n",
    "cv_scores = []\n",
    "cv_result = []\n",
    "i = 0\n",
    "\n",
    "for train_indice,val_indice in validation_tuple_list:\n",
    "    #print trade_train_val.iloc[train_indice]['month'].unique(),trade_train_val.iloc[val_indice]['month'].unique()\n",
    "    #print trade_train_val.iloc[train_indice].shape,trade_train_val.iloc[val_indice].shape\n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = trade_train_val.iloc[train_indice,:] , trade_train_val.iloc[val_indice,:] \n",
    "    #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = trade_label.iloc[train_indice].values, trade_label.iloc[val_indice].values\n",
    "\n",
    "    \n",
    "    preds, model = runLGBM(dev_X, dev_y, val_X, val_y,feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=400,watch_dict=result_dict,feval = f_beta_01)\n",
    "\n",
    "    #result_f_beta = f_beta_01(val_y.values, preds>0.5)\n",
    "    result_f_beta  = fbeta_score( val_y,preds > 0.5, 0.1)\n",
    "    \n",
    "    cv_scores.append(result_f_beta)\n",
    "    cv_result.append(result_dict)\n",
    "    i+=1\n",
    "    print'f_beta score for the turn '+str(i)+' is '+str(result_f_beta)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finding the best iteration\n",
    "pd_list = []\n",
    "for dic in cv_result:\n",
    "    pd_list.append(pd.DataFrame(dic['test']))\n",
    "for i in range(len(pd_list)):\n",
    "    pd_list[i].columns = pd_list[i].columns+'_'+str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_result = pd.concat(pd_list,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_result['auc_avg'] = validation_result.apply(lambda x : np.mean([x.auc_0,x.auc_1,x.auc_2,x.auc_3,x.auc_4]),axis = 1)\n",
    "validation_result['fbeta_avg'] = validation_result.apply(lambda x : np.mean([x.fbeta_score_01_0,x.fbeta_score_01_1,\n",
    "                                                                     x.fbeta_score_01_2,x.fbeta_score_01_3,\n",
    "                                                                     x.fbeta_score_01_4]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "print validation_result['auc_avg'].idxmax()\n",
    "print validation_result['fbeta_avg'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating the result using the best parameters\n",
    "#using binary logloss and auc and picking up the feature importance\n",
    "preds, _ = runLGBM(train_X, train_y, test_X, feature_names=features,verbose=100,eta=0.02,\n",
    "                          early_stop=None,num_rounds=102,watch_dict=result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../kaggleData/JD_logging/'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_path = '../../kaggleData/JD_logging/result/'\n",
    "config.result_path = result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17875, 2)\n"
     ]
    }
   ],
   "source": [
    "test_rowkey = pd.read_pickle(data_path+'trade_test_rowkey.pkl')\n",
    "pred_label = pd.Series(preds > 0.5)\n",
    "result_set = pd.DataFrame(test_rowkey)\n",
    "result_set['is_risk'] = pred_label.astype(int)\n",
    "\n",
    "print result_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(pred_label,result_path+'basic_detail_and_comparing.pkl')\n",
    "result_set.to_csv(result_path+'basic_detail_and_comparing.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBM',\n",
       " '__doc__',\n",
       " '__module__',\n",
       " 'data_path',\n",
       " 'f_beta',\n",
       " 'feature_dict',\n",
       " 'feature_path',\n",
       " 'result_path',\n",
       " 'single_module_validation_indice_set',\n",
       " 'trade_train_size']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del config.f_beta\n",
    "del config.LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(config,'config.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
